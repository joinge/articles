
%===============%                               %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%
% DOCUMENTCLASS %                                See full option description in "mytemplate.cls"
%===============%                               %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%
 
\documentclass[
   article                                      % Document type (non-standard)
 , 12pt                                         % Text size
%  , draft
%  , final                                        % Quality
 , xelatex                                      % Use the XeLaTeX compiler
%  , biblatex                                     % Use 'biblatex' for references (best by far)
 , bibtex                                       % Use 'bibtex' for references (oldschool :)
%  , movie
%  , notodos                                      % Disable todos
 , layout
%  , defaultformat                                % Attempt to use default formatting options
%  , glossary                                     % Use a glossary
]{common/mytemplate}

% \bibliography{references}
\hypersetup{
   bookmarksopen=true
 , bookmarksopenlevel=2
}
% Load the references.bib file
% \bibliography{references}



\begin{document}
% \setlength{\headrulewidth}{0.0pt}

%~~ TitlePage ~~%                               %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%
\thispagestyle{empty}
\pagenumbering{arabic} %Normal numbers

\begin{center}

{\Large Design Suggestion}\\[0.2cm]
{\itshape for a}\\[0.2cm]
{\Large GPU Based Sonar Template Simulator}\\[2cm]
{\itshape by}\\[0.2cm]
\begin{minipage}{0.35\textwidth}\small\centering
Jo Inge \textsc{Buskenes}\\
\textnormal{\color{SeaGreen}joibu (at) ifi.uio.no}
\end{minipage}
\begin{minipage}{0.35\textwidth}\small\centering
Jon Petter \textsc{Åsen}\\
\textnormal{\color{SeaGreen}jpaasen (at) ifi.uio.no}
\end{minipage}\\[2cm]
{\itshape on the behalf of}\\[0.2cm]
\begin{minipage}[t]{0.49\textwidth}\centering
  \centering\includegraphics[height=3cm]{gfx/FFILogo.png}\\
  \textsc{The Norwegian Defence Research Establishment (FFI)}
\end{minipage}\\[0.5cm]
\begin{minipage}[t]{0.4\textwidth}\small\centering
Øivind \textsc{Midtgård}\\
\textnormal{\color{SeaGreen}oivind.midtgaard (at) ffi.no}
\end{minipage}
\begin{minipage}[t]{0.4\textwidth}\small\centering
Herman \textsc{Midelfart}\\
\textnormal{\color{SeaGreen}herman.midelfart (at) ffi.no}
\end{minipage}\\[0.3cm]
\begin{minipage}{0.32\textwidth}\small\centering
Roy Edgar \textsc{Hansen}\\
\textnormal{\color{SeaGreen}roy-edgar.hansen (at) ffi.no}
\end{minipage}
\vfill
\small
Revision 2, \today
\end{center}


\clearpage
\pagestyle{fancy}
%~~ Sections ~~%                                %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%


\section{Introduction}

Template matching is a common technique used when classifying objects in SAS images. The principle is to isolate an image segment containing an object of interest, correlate it with a set of template images, and assign it to the class of the template yielding the highest correlation coefficient. The challenge is to come up with a suitable set of template images, considering the vast span of possible seafloor and object characteristics.

FFI target this challenge by using a sonar simulator that can take a seafloor model or data as input, in which various target objects are postitioned in various ways. For each object configuration the scene is rendered and the result added to the template set. But while producing templates on-the-fly is a very flexible solution, it is also computationally demanding.

This is why we are investiging the feasibility of using a GPU to speed up the simulations.

\begin{figure}[b]
\graphicsAI[drawing,width=\linewidth]{gfx/specs.svg}
\caption{Simulator specifications.}\label{specs}
\end{figure}

\section{Specification}

Most of the specifications received from FFI are illustrated in Figure \ref{specs}. 


\section{Design Suggestion}

As detailed below, in this revision we have decided to add a couple alternative designs that is more flexible and able to handle effects such as geometric layover and multipath.
% This is to better be able to simulate geometrical sonar imaging effects such as layover. We will describe both the original suggestions and the updated design here.

\subsection{The Initial Suggestion}

In the original specification we put forth two possible approaches to implementing the mentioned simulator (figure \ref{implementation}). We envisioned to either

\begin{figure}[b]
\begin{narrow}{-2.3cm}{-2.3cm}
\graphicsAI[drawing,width=\linewidth]{gfx/simulator.svg}
\end{narrow}
\caption{Two possible implementation strategies.}\label{implementation}
\end{figure}

\begin{itemize0}
\item use OpenGL to produce depth-maps of the scene, and CUDA/OpenCL to illuminate it as a sonar would, or
\item use OpenGL to render the full scene with lighting.
\end{itemize0}

In each of these cases the simulator takes a seafloor and target model as input, and generates a simulated sonar image, as well as perform template correlation if desired. For the first step of setting up the 3D scene, move objects and cameras around, and render it using a GPU, we initially believed OpenGL to be the better choice. OpenGL was made for this specific task, is cross-platform, feature-rich, well-matured and tuned to peak performance to meet the heavy needs of the gaming industry.

But can we accurately simulate a sonar system using a framework designed to simulate optics?


\subsection{Simulating a sonar scenario using optics}

\begin{figure}[b]
\begin{narrow}{-2.3cm}{-2.3cm}
\graphicsAI[drawing,width=\linewidth]{gfx/simulation_setup.png}
\end{narrow}
\caption{Two possible implementation strategies.}\label{simulation_setup}
\end{figure}

As a preliminary study we created a 3D model of a manta mine and a cylinder located on a flat ground surface (fig. \ref{simulation_setup}). Here we placed the camera 6 meters above the surface looking down on it. The light source was put at a 50\;m distance and set up without falloff, and the light hits the centre of the scene at an angle of 10$^\circ$. The manta mine was made according to specifications with 48\;cm height and 98\;cm ground diameter, the same applies to the cylinder. The distance between the two objects was 1\;m.

\begin{figure}[b]
\begin{minipage}[c]{0.49\linewidth}
\graphicsAI[drawing,width=\linewidth]{gfx/simulation_mask.png}
\centering\itshape Simulation mask
\end{minipage}\mbox{}\hfill
\begin{minipage}[c]{0.49\linewidth}
\graphicsAI[drawing,width=\linewidth]{gfx/simulation_object.png}
\centering\itshape Simulated object
\end{minipage}
\graphicsAI[drawing,width=\linewidth]{gfx/simulation_optical.png}
\centering\itshape Combined image\vspace{5pt}
\caption{Optical rendering.}\label{s}
\end{figure}

To simulate this scene we combine a normal optical simulation with a mask image. The mask image scene is set up with a powerful light source and highly diffractive surfaces, which causes everything that is hit by light to obtain a high intensity value. Only direct light is processed, so shadows will come out as empty. In the scene with the simulated object material properties are adjusted to reflect a more reasonable amount of light, and a light insensitive background was chosen. The two images was finally combined by colour multiplication.

Are such an approach accurate enough? Or do we need to consider layover, multipath, or other effects as well?


\subsection{Layover and multipath}

If layover and multipath are important, then the techniques used to simulate the previous images can not be used. Then we believe that a pure CUDA / OpenCL implementation is the better choice, but how these should be designed depends on the effects we wish to implement. For layover one could launch a thread for each pixel in the image, let it find all the points in the image that contributes with direct returns to that pixel, and sum the contributions up. For multipath a ray tracer customized for sound is likely the better option.


In addition we see that each approach shares the same initial steps. The risk of choosing an OpenGL-only implementation is therefore reduced, since we may easily switch to the CUDA implementation if an OpenGL prototype fails to produce the desired results.





Our original idea was to use OpenGL to produce depth-maps of the object and (optionally) the seafloor, and then use CUDA to compute how a sonar array would illuminate this scene. However, since were only interested in pixel intensities, and sound may be treated as ``light'' with reasonable accuracy, we believe that OpenGL can be used to simulate the entire scene. This way we may support whatever OpenGL supports with little extra effort. The gaming industry demands speed, so such a simulator should also be very fast.

The main advantage of the CUDA implementation lies in its flexibility. If desired, it can be modified to handle sound propagation in non-ideal mediums, penetrable objects, signal multipath, diffraction and phase-dependent effects such as speckle. The drawback is the added code complexity and development time.

We have compared the two methods in Table \ref{comparison}.

\begin{table}[t]\centering
\begin{tabular}[c]{l l l}\hline
\rowcolor{tabBlue}                  & CUDA/OpenGL    & OpenGL only \\\hline
Development time (per person)       & 6 weeks        & 4 weeks     \\
Development complexity              & Moderate       & Low \\
Amount of code                      & More           & Less \\
Maintainability                     & Moderate       & Moderate \\
Code readability                    & Moderate       & Moderate \\
Signal model                        & Arbitrary      & Light rays  \\
Sound$\rightarrow$light calibration & Not necessary  & Necessary(?) \\
Multipath support                   & Possible       & Hard \\
Speckle support                     & Possible       & Hard \\
Diffraction support                 & Possible       & Hard \\
Complex image                       & Easy           & Hard \\
ATI/nVidia support                  & nVidia only    & Both \\
\end{tabular}
\vspace{5pt}\caption{Comparison of implementation approaches}\label{comparison}
\end{table}


\section{Final thoughts}

Do we need to include effects such as layover and multipath in our simulations?

If the answer to this is no, then we propose using a OpenGL to simulate the scene, and model the array as lightsources. Geometrical effects can be added in the post-processing using CUDA / OpenCL, but extending the simulator to support other sonar specific effects will likely be hard. This approach with also be very portable, and should not require too much effort.

On the other hand, a CUDA / OpenCL implementation can handle anything. But does it need to? We should be fairly certain what we aim for here, since the various advanced effects calls for completely different implementation strategies.

We aim to start development in July. The goal is to have an OpenGL prototype ready within a couple weeks, and from there decide which approach to go for. We propose monthly progress reports and meetings to discuss further development.




\newpage

\section{Ideas for paper}

\begin{itemize}
\item With effects such as layover, shadows, limited resolution (detail retention capability), and complex object and surface shapes, computing the actual scenario based on the sonar image is hard.
\item Better to perform fast, recursive simulations instead?
\item Adaptive images in a video makes it much easier to understand what is going on. Need much better erfora
\item Litits: massive storage, fixed templates, amplitude/noise sensitive
\item Alternatives: Pattern recognition (hard to extract decent features, selection, fixed templates) and model-based (massive computational requirements)
\item Why models? Hard to get accurate models from limted amount dat, targets not always availagme, variations in target/terrain.
\item CAD models. Sufficient complexity? Materials? Transparency, characterisation, multilauers.
\item Accuracy vs. comp. speed.
\end{itemize}

\newpage

% \section{Documentation}

% \input{ffi-documentation}
\end{document}

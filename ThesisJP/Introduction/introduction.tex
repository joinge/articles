\section{Motivation}
A rapid development in computer game technology and accompanying programming languages have recently provided researchers with small personal super computers, comprised in a single graphics card (\nom{GPU}{Graphics processing unit}). The latest graphics cards\footnote{As of January 2014.} from both \nom{Nvidia}{Graphics card producer} and \nom{AMD}{Graphics card producer} provide close to 6 T\nom{FLOPS}{Floating point operations per second} single precision and 1.5 TFLOPS double precision computations. For double precision this is more than the worlds most powerful supercomputer could provide in 1998.

This immense rise in computational power and improved programmability are currently changing how ultrasound imaging systems are designed. Algorithms which previously had to be implemented in hardware for performance reasons can now be implemented in software. And algorithms, either too complicated or costly to implement in hardware, and where a software implementation was thought to be too computationally heavy for real-time use, becomes realizable. It is clear that high-performance programmable processors, like the GPU, already have and will continue to make future ultrasound imaging systems more flexible, cheaper to produce, and equipped with even more cutting-edge processing.

The Capon beamformer  is a good example of an algorithm which has been highly studied for the last decade for the application of medical ultrasound imaging, but where the number of calculations was thought to be too high for real-time processing to happen any time soon. No wonder, to achieve real-time processing for e.g. cardiac ultrasound imaging, an effective processing rate of around 100 MFLOPS is required. This number, as explained in Section \ref{sec:adaptbf}, also grows with larger subarrays, an increasing number of samples, and higher frame rates.  Nevertheless, with modern GPUs, these levels of processing are finally available within a single card. When researchers are exploring new algorithms for ultrasound imaging it is therefore important to keep the architecture of parallel accelerators in mind. If a new complex algorithm is suppose to run in real time it needs to fit the programmable and parallel pipeline of modern ultrasound scanners.

\section{Aims of study}
The overall aim of this study has been to investigate the possibility of utilizing GPUs for advanced processing in an ultrasound imaging system. 

Main focus have been the Capon beamformer, and the problem of making this computationally intense algorithm available for real-time ultrasound imaging (\textbf{Paper\,I} and \textbf{II}). However, two additional methods were also explored. The first is adaptive visualization of cardiac ultrasound volumes (\textbf{Paper\,IV}) and the latter is simulation of dense ultrasound pressure fields (\textbf{Paper\,V}). Both share the property of being computationally complex, but on the other hand they consist of many independent computations which makes them perfectly suited for parallel GPU acceleration.

Well on my way into the project, when a real-time Capon beamformer was realized, and loops of images for the first time were processed at real-time frame rates, new issues where discovered and had to be solved. This led to a more theoretical study of the Capon beamformer in \textbf{Paper\,III}, with special attention on how to obtain high lateral resolution while preserving the important shift-invariant property of ultrasound imaging. Shift-invariant behavior is crucial if the method is ever to be applied for live scanning. 

%\subsubsection{Accelerate the Capon beamformer to facilitate real time imaging}

%\subsubsection{}

\section{Summary of papers}

\subsection{Paper\,I}
\textbf{An Optimised GPU Implementation of the MVDR Beamformer for Active Sonar Imaging}\\
J.\:I.\:Buskenes, \textbf{J.\:P.\:\AA{}sen}, C.-I.\:C.\:Nilsen and A.\:Austeng\\
{\it IEEE Transactions on Oceanic Engineering, submitted.}\\\\
The first paper describes in details how the Capon beamformer was mapped to GPU architecture. Even though the paper is written within the field of active \nom{sonar}{SOund Navigation And Ranging (usually under water)} imaging, the depicted implementation is applicable to a vast range of active imaging systems. A similar discussion for cardiac ultrasound imaging can be found in \textbf{Paper\,VI}.  Active sonar imaging typically differs from medical ultrasound imaging by a lower real-time requirement and fewer array elements. This makes it somewhat easier to reach the goal of real-time processing. 

The estimation of the spatial covariance matrix receives special attention in this study. In previous literature on Capon beamforming the matrix inversion has always been regarded as the most computationally complex step. In this paper we show that estimation of the sample covariance matrix is actually the most complex part when spatial and temporal smoothing with common parameters are included. It is then shown how the arithmetic complexity of this estimation process can be reduced from cubic to square. Finally, an in-depth analysis of the arithmetic throughput on multiple platforms is given. Despite our effort, the number of effective FLOPS is only 4 \% and 14 \% of the theoretical throughput of the target GPU for the matrix equation solver and covariance estimator respectively. Still, the reported throughput of 1 Mpx/s on a high-end GPU is enough to provide real-time processing for common sonar scan sequences.

\subsection{Paper\,II}
\textbf{Implementing Capon Beamforming on a GPU for Real-Time Cardiac Ultrasound Imaging}\\
\textbf{J.\:P.\:\AA{}sen}, J.\:I.\:Buskenes, C.-I.\:C\:Nilsen, A.\:Austeng and S.\:Holm\\
{\it IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control, vol. 61, no. 1, pp. 76-85, Jan. 2014.}\\\\
The second paper aims at implementing real-time Capon beamforming for cardiac ultrasound imaging. Achieving this will facilitate further study of the method's \textit{in vivo} performance. This is something which has been stated as further work in many publications on Capon beamforming for medical ultrasound imaging the past decade. In \textbf{Paper\,I} arrays with no more than 32 elements were investigated. A linear array for cardiac ultrasound imaging typically has 64 or more elements. In \textbf{Paper\,VI}, which is summarized in \textbf{Paper\,II}, it is shown that our implementation from  \textbf{Paper\,I} does not reach the level of throughput required for real-time Capon beamforming of cardiac ultrasound imaging. The matrices that have to be inverted become to large, and the frames that need to be processed per second are too many.

In this paper, to reduce the matrix size, it is taken advantage of the beamspace version of the Capon beamformer (\nom{BS-Capon}{Beamspace capon beamforming}), which is implemented on the GPU. For parameters previously derived to give similar performance for BS-Capon and element-space Capon (\nom{ES-Capon}{Element space capon beamforming}), we show that real-time BS-Capon beamforming is feasible for cardiac ultrasound imaging. The reported processing throughput is able to keep up with the acquisition frame rate in a typical cardiac ultrasound imaging system equipped with 64 and 96 element linear arrays.  \textbf{Paper\,II} and \textbf{VI} also presents, for the first time, videos where the ES-Capon and BS-Capon beamformer have been applied on loops of simulated and \textit{in vivo} medical ultrasound images.

\subsection{Paper\,III}
\textbf{Capon Beamforming and Moving Objects - An Analysis of Lateral Shift-Invariance}\\
\textbf{J.\:P.\:\AA{}sen}, A.\:Austeng and S.\:Holm\\
{\it IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control, submitted.}\\\\
In the third paper we study the shift-invariant property of an imaging system based on the Capon beamformer. As mentioned, shift-invariant imaging is essential if the method is ever to be adopted. The paper was written based on observations of aliasing artifacts when imaging bright point scatterers \textit{in vitro} and in simulations. The point scatterers were observed to twinkle like stars in the sky. In earlier work on Capon beamforming for medical ultrasound imaging the real-time nature of ultrasound imaging has often been ignored, and a large degree of oversampling on transmit might have been applied without being clearly stated. Oversampling on transmit is not an option if the imaging modality is used to image rapidly varying objects. Smooth presentation of probe motion is equally important since real-time user interaction is one of the key selling points of ultrasound imaging. The frame rate should therefore be higher than 10 frames per second.

Further it has been investigated how the Capon beamforming achieves its super resolution, and how this makes it highly sensitive to differences between the assumed steering vector and the signal propagation vector. Earlier work, focusing on single images, has typically referred to this effect as speed-of-sound errors, however, it also comes naturally into play when objects moves from frame to frame and the beam density is insufficient. With a narrowband and farfield model it is shown that the Capon beamformer suffers from beam-to-beam gain variations as large as 27 dB for parameters previously used to obtain high resolution medical ultrasound images.  To obtain the same lateral gain variations as with \nom{DAS}{Delay-and-sum beamforming} beamforming, 25 times oversampling is shown to be required. For broadband nearfield simulations the same gain variations are observed. Finally we show that the gain variation can be reduced, hence improved shift-invariance, by oversampling on receive using phase rotation steering. This is achieved without affecting the acquisition frame rate and with a minor increase in computational complexity. The method is successfully applied on simulations and \textit{in vitro} phantom data.

\subsection{Paper\,IV}
\textbf{Adaptive Volume Rendering of Cardiac 3D Ultrasound Images - Utilizing Blood Pool Statistics}\\
\textbf{J.\:P.\:\AA{}sen}, E.\:Steen, G.\:Kiss, A.\:Thorstensen and S.\:I.\:Rabben\\
{\it Proc. SPIE Medical Imaging 2012, vol. 8320, pp. 832008.}\\\\
The fourth paper propose an adaptive volume rendering method based on statistics derived from the blood pool of the left ventricle. Noise located in the blood pool tends to occlude cardiac tissue when rendered in 3D, and is often impossible to remove by adjusting global rendering parameters. This because ultrasound signals have high variability within blood as well as high variability within tissue, even when heavily smoothed. Delineation of the blood pool is done by a state estimation algorithm, capable of tracking the endocardium in real time. The final visualizations are compared, with respect to location of tissue, by using a state-of-the-art endocardium segmentation tool. The paper presents both quantitative and qualitative results supporting the method's improved capabilities of reducing tissue dropouts and spurious structures inside the blood pool, leading to a maximized amount of visible endocardium tissue. The proposed method is implemented on a GPU with real-time frame rates as the result. This results shows that with modern GPUs it is possible to add more advanced visualization to an ultrasound imaging system and still have real-time performance.

\subsection{Paper\,V}
\textbf{Huygens on Speed: Interactive Simulation of Ultrasound Pressure Fields}\\
\textbf{J.\:P.\:\AA{}sen} and S.\:Holm\\
{\it Proc. IEEE Ultrasonics Symposium 2012, pp. 1643-1646.}\\\\
The fifth paper presents an interactive simulations tool capable of simulating dense pressure fields from ultrasound arrays in real time. Simulation tools are heavily used by researchers in order to test out new algorithms and to deduce the performance of new array designs prior to manufacturing. However, dense simulations involve extensive calculation and computational time. With the presented simulator we aim at reducing the time needed for calculating pressure fields by means of GPU acceleration. The tool is based on Huygens' principle which describes diffraction caused by a slit as the superposition of several point sources located inside the opening. Thus, the simulator works by accumulating the contribution from a collection of point sources in a set of observation points. How the source and observation points are laid out is left for the user to decide. Point sources positioned along a line will for instance simulate an ultrasound array. The simulator is linked with both a Paint-like interface for interactive drawing of arrays, and a Matlab interface for precise scripting of array configurations. The main contributions in this paper is the increased performance of the GPU implementation compared with a CPU and Matlab\footnote{The Ultrasim toolbox \todo{add citation}} version. Second, the paint-like interface provides a neat way of demonstrating array beamforming principle in real time. We believe this to be of great value both for array designers and teachers.

\section{Main contributions}
The main contributions of this thesis are:
\begin{enumerate}
\item a GPU implementation of the Capon beamformer.
\item a GPU implementation of the beamspace Capon beamformer.
\item that real-time beamspace Capon beamforming is achieved for cardiac ultrasound imaging.
\item the first investigation of Capon beamforming applied on multiple frames in medical ultrasound imaging (simulated, \textit{in vitro}, and \textit{in vivo}).
\item an investigation of shift-invariance when the Capon beamformer is applied on consecutive frames.
\item a method for improved shift-invariance of the Capon beamformer when applied to medical ultrasound imaging.
\item a method for reduced blood-pool noise in volume renderings of cardiac ultrasound volumes.
\item a GPU implementation of this adaptive volume rendering method.
\item a GPU implementation of simple Paint-like simulation tool for rapid visualization ultrasound pressure fields.
\end{enumerate}
In addition, the thesis provides several discussions on how to utilize the GPU to accelerate advanced ultrasound imaging algorithms. 

\section{Discussion and future work}
Even with all our effort in \textbf{Paper\,I} we were only able to achieve a fraction of the maximum throughput of the target GPU. This result shows how hard it is to reach the theoretical level of throughput, and that how close one can get is highly algorithm depended. It might be ways to improve on these numbers, but both the solver and covariance estimation step consist of several points where fine granular synchronization and serialized instructions are needed. This will restrict even the most fine tuned implementation from reaching the maximum throughput of the GPU. An interesting observation can be found in Fig.\,10 of \textbf{Paper\,I}. Here we see how the achieved throughput of the covariance estimation kernel is more than three times higher than the theoretical throughput of a modern, high-end, \nom{CPU}{Central processing unit}. This clearly shows the benefit of modern GPU computing.  Solving was performed by a batched Gauss Jordan solver implemented by Nvidia. In our work we focused on the covariance estimation step, and did not try to beat Nvidia at home. Nevertheless, with the measured throughput in mind, a natural next step would be to analyze the current solver, and figure out if any further optimization is possible. Since the sample covariance matrix is hermitian, a solver based on Cholesky decomposition might also help to improve the solver's throughput.
\\\\
In \textbf{Paper\,II} we focused on achieving real time Capon processing for cardiac ultrasound by implementing the BS-Capon beamformer on a GPU. However, we also present the first medical ultrasound loops processed with ES- and BS-Capon beamforming.  The paper does not provide any detailed evaluation of the method's \textit{in vivo} performance. Yet, initially it has been proven hard to transfer all results obtained in simulations to \textit{in vivo} images. The improvements seen are minimal, especially with the number of calculations in mind. The beamformers are clearly able to decrees the lateral width of lateral point scatterers and thin structures \textit{in vivo}, and to sharpen step edges. On the other hand, the overall contrast is visually not improved and sometimes it is worse (Fig.\,6b of \textbf{Paper\,II}). Since the Capon beamformer only affect directional noise, it is clear that contrast will get worse in low \nom{SNR}{Signal-to-noise ratio} situations when signal cancellation occurs. The oversampling approach presented in \textbf{Paper\,III} might improve on this, but it will only reduce signal cancellation if the phase shifts across the aperture are close to linear and small. Another issue is that bright points with a wide lateral profile exhibits better visual contrast when surrounded by speckle noise than points with narrow lateral profiles. In future work a detailed investigation of why some results, especially the contrast, obtained in simulations are not transferable to \textit{in vivo} needs to be performed. It will also be crucial to show larger improvements \textit{in vivio} than what is presented in \textbf{Paper\,II}. Both to justify all our computations, and to show an image which has both highly improved resolution and contrast. As pointed out at the end of \textbf{Paper\,II}, cardiac ultrasound imaging might not be the best modality for Capon beamforming. Cardiac ultrasound imaging was mainly selected because it is the medical ultrasound modality which requires most calculations per second. An application where the focus is detection of closely spaced point targets, might be better suited. A better suited adaptive beamformer for cardiac applications might be the low-complexity adaptive beamformer (\nom{LCA}{Low complexity adaptive (beamformer)} beamformer), where the Capon optimization problem is applied on a set of predefined windows. This method has linear complexity and shares many properties with the Capon beamformer. If only minor improvements are obtained, it would be easier to ignore this fact if the algorithm is less computationally costly. Finally, it would also be interesting to see how the Eigenspace-based Capon beamformer performs on cardiac images, and how its absence of a distortionless criterion will influence the image spatially and temporally. The work in \textbf{Paper\,II} made it clear that interesting findings are done when users are able to watch the temporal behavior of an algorithm. This led us to the work of \textbf{Paper\,III}. 
\\\\
In \textbf{Paper\,III} we investigate the inherent self nulling involved with Capon beamforming, and how this effect comes naturally into play when the beamformer is subjected to linear steering vector errors caused by lateral undersampling. These errors are naturally reduced when the lateral sampling is increased. This simple observation is something which has been missing in the literature on Capon beamforming for medical ultrasound imaging. The reason could be ignorance or its possible negative impact on imaging frame rate. A lack of studies where Capon beamforming is performed on consecutive frames might also explain the lack of comments. Fortunately, as shown in \textbf{Paper\,III}, it is possible to maintain the same frame rate as with DAS beamforming by applying oversampling on receive using a set of steering vectors (phase delays). It also turns out that more matrix inversions are not needed either. Oversampling on receive will, however,  increase the penalty of applying post-processing, like filtering,  on scan-grid data. %The time taken to convert data from a polar scan grid to a Cartesian display grid will also increase. The Cartesian grid should also have high resolution in order to preserve the un-sharpening introduced by Capon beamforming. 
As just mentioned in the discussion of \textbf{Paper\,II}, reduced signal cancellation should prevent contrast from degrade to less than the contrast obtain with DAS. It will, however,  not correct for signal cancellation caused by phase aberrations. At best it will correct for the linear term introduced by the aberrator if the term is small.
With improved shift-invariance it will also be interesting to see if high resolution beamforming could act as a post-processing step for other algorithms. For example to increase the precision of speckle and edge tracking. In the case where the image is generated for post processing it does not need to be visually pleasant anymore, as long as signal cancellation is avoided. Good looking speckle, or DAS-like speckle, has been the driving force behind many of the robustification techniques and the default parameters seen in the literature. Hence, more aggressive parameters might be used if the image produced is intended as input to another algorithm and not for the human eye.
\\\\
%Objections to \textbf{Paper\,IV} includes its inherent chicken-or-egg dilemma. The visualization is adjusted based on the data acquired by a user. The user sees the visualization and adjust scanning based on the visual input. This recursive behavior suggest that the method is best suited for post-processing when data has been recorded and saved. 
%Does data need to be saved in order to perform tracking?
One limitation of the algorithm described in \textbf{Paper\,IV} is its dependence on a successful tracking. If the tracking fails the proposed method will fail.  Another issue is the view-dependent visibility, where an object could become visible or disappear while rotating or if the local statistics change a lot during the cardiac cycle. Even if the method successfully removes noise, this means that the rendering will become non-intuitive to interact with and unrealistic to watch. However, the method could still be used to clean up still images of standard cardiac views. The paper does also propose an interesting method for automatic tuning of rendering parameters. Figure 3d in \textbf{Paper\,IV} actually shows that an optimal threshold could be found based on global and not only local statistics. Even though the visualization based on global statistics has more errors, with respect to endocardium visibility, the tuning of the opacity function is still fully automatic if an iterative search for the minima in Figure 3d is performed. A global opacity transfer function will assure a rendering which are realistic, but it will still be dependent on a successful tracking for the auto-adjustment to work. An automatically tuned opacity function based on global statistics combined with an improved smoothing scheme is likely to be better suited for cardiac ultrasound imaging than a local opacity transfer function. A local opacity transfer function is just to extreme to be clinically robust. It would also be interesting to see if statistics based on the window selected by the Capon or the LCA beamformer could be utilized to adjust the opacity. It should also be possible to use this statistic as input to image filtering. An adaptively selected window will be symmetric in homogeneous regions and left-right shifted close to tissue interfaces. In that way we can apply less filtering and higher opacity on edges. If this will be different than just looking at neighboring pixels in a smoothing filter is to be seen.
\\\\
The fifth paper stands out from the other papers by not dealing with an adaptive processing technique. It is still, however, centered around the topic of implementing algorithms for ultrasound imaging on GPUs. Ultrasound simulations are typically used for research and sometimes also to pre-calculate configurations of a given scan sequence, for instance to achieve a certain pressure in a given area. The continuously growth in computational power will, in the future, make it possible to evaluate a scan sequence on the fly, removing the need for lookup tables. Estimation of the mechanical and thermal index could also be improved. Achieving higher processing speed for an excising algorithm by implementing it on a new architecture is not academically relevant in its own. It has to be combined with either a good analysis of what special adjustments that had to be made to the algorithm in order for the increase to happen or a suggestion of how to utilize the speed gained. These are points we have tried to answer in both \textbf{Paper\,I}, \textbf{II},  \textbf{IV}, and \textbf{V}.  In \textbf{Paper\,V} the increased speed made an interactive ''Paint-program'' feasible. As of January 2014 the simulator has been download 200 times and counting. It also has close to a "whopping" 1000 views on youtube. 
\\\\
Finally it is worth mentioning that the code for both the Capon beamformer\footnote{github.com/jpaasen/cos} and the ultrasound field simulator\footnote{github.com/jpaasen/hos} have been made open source and is available on github. 
\endinput

\newif\ifTODO\TODOfalse                        % Use todo notes?

%===============%                               %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%
% DOCUMENTCLASS %                                See full option description in "mytemplate.cls"
%===============%                               %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%
 
\documentclass[
a4paper,10pt
]{common/ica2013_2}

% \usepackage[utf8x]{inputenc}
\usepackage[table,dvipsnames,svgnames]{xcolor}
\usepackage{titlesec}

\newcommand\Fig[1]{Fig. \ref{#1}}

\newcommand\Grey[1]{{\color{Grey}#1}}
\newcommand\Red[1]{{\color{Red}#1}}
\newcommand\Blue[1]{{\color{Blue}#1}}
\newcommand\DarkBlue[1]{{\color{DarkBlue}#1}}
\newcommand\LightBlue[1]{{\color{LightBlue}#1}}
\newcommand\Brown[1]{{\color{Brown}#1}}
\newcommand\Green[1]{{\color{Green}#1}}
\newcommand\SeaGreen[1]{{\color{SeaGreen}#1}}
\newcommand\Yellow[1]{{\color{yellow}#1}}
\newcommand\Orange[1]{{\color{orange}#1}}

\ifTODO
   \newcounter{todoidx}
   \definecolor{todobackground}{rgb}{0.95,0.95,0.95}
   \setlength\marginparsep{1pt}
   \setlength\marginparwidth{50pt}
   \newlength\marginparwidthsmall
   \setlength\marginparwidthsmall{\marginparwidth}
   \addtolength\marginparwidthsmall{-7pt}
   \newcommand\todo[1]{%
      \addtocounter{todoidx}{1}%
      {\color{Red}\bf(\thetodoidx{})}%%\fbox{\bf\thetodoidx{}}}%
      \marginpar{%
         {\vspace*{-10pt}\color{Red}\fbox{\bf\thetodoidx{}}}\\%
         \fcolorbox{red}{todobackground}{\parbox{\marginparwidthsmall}{\scriptsize #1}}}}

   \newcommand\todopar[1]{\fcolorbox{red}{white}{\parbox{0.97\linewidth}{#1}}}
\else
%    \usepackage[disable]{./todonotes} 
   \newcommand\todo[1]{}
\fi

\newcommand\nn{\nonumber\\}

\newcommand\nmat[1]{\begin{matrix}#1\end{matrix}}
\newcommand\bmat[1]{\begin{bmatrix}#1\end{bmatrix}}
\newcommand\case[1]{\begin{cases}#1\end{cases}}
\newcommand\textbox[2]{\footnotesize\text{\parbox{#1}{\centering\emph{#2}}}}

\newcommand\rand{\text{rand}}
\newcommand\randn{\text{randn}}
\newcommand\rect{\text{rect}}
\newcommand\sinc{\text{sinc}}
\newcommand\tr{\text{tr}}
\newcommand\adj{\text{adj}}

% \newcommand\max{\text{max}}
\newcommand\argmin[1]{\text{arg}\,\underset{#1}{\text{min}}}

\newcommand\qqquad{\quad\qquad}
\newcommand\qqqquad{\qquad\qquad}

\renewcommand\l[1]{\left#1}
\renewcommand\r[1]{\right#1}

% {\text{\parbox{1.5cm}{\centering volume hyper- sphere}}}

%Keyword colouring:
\newcommand\kw[1]{#1}
\newcommand\parm[1]{#1}%\color{Black}#1\color{Black}}

\newcommand\of[1]{\scriptstyle(\parm{#1})\displaystyle}
\newcommand\df[1]{\scriptstyle[\parm{#1}]\displaystyle}
\newcommand\var[3]{#1_\text{#2}\of{#3}}

\newcommand\diag{\text{diag}}

% \raisebox{lift}[extend-above-baseline][extend-below-baseline]{text}
\newcommand\mt[1]{\text{\emph{#1}}} %mt = mathtext
\newcommand\mathnorm{\textstyle}
\newcommand\mathbig[1]{\displaystyle#1\mathnorm}
\newcommand\mathsmall[1]{\scriptstyle#1\mathnorm}
\newcommand\mathtiny[1]{\scriptscriptstyle#1\mathnorm}
\newcommand\sfrac[2]{\scriptstyle\raisebox{0.25pt}[0pt][0pt]{$\frac{#1}{#2}$}\mathnorm}
\newcommand\nfrac[2]{\textstyle\frac{#1}{#2}\displaystyle}

\newcommand\sumu[1]{\sum\limits^{#1}\,}
\newcommand\suml[1]{\sum\limits_{#1}\,}
\newcommand\sumb[2]{\sum\limits_{#1}^{#2}\,}

\newcommand\produ[1]{\prod\limits^{#1}\,}
\newcommand\prodl[1]{\prod\limits_{#1}\,}
\newcommand\prodb[2]{\prod\limits_{#1}^{#2}\,}

\newcommand\defeq{\overset{\underset{\mathrm{def}}{}}{=}}

%Math macros:
\newcommand\diff[2]{\frac{\kw{d}\,\textstyle #1\scriptstyle}{\kw{d\parm{#2}}}\displaystyle}
\newcommand\ddiff[2]{\frac{\kw{d^2}\,\displaystyle #1\scriptstyle}{\kw{d\parm{#2}}^2}\displaystyle}

\renewcommand\d[1]{\scriptstyle\kw{\,d\parm{#1}}\displaystyle}

% These commands are mutually exclusive. Remember to "renew" in v2.
\newcommand\intb[4]{\int\limits_{#3}^{#4} #1 \d{#2}} % \int{exp}{var}{from}{to}
\newcommand\intl[3]{\int\limits_{#3} #1 \d{#2}} % \int{exp}{var}{for all}
\newcommand\intu[2]{\int #1 \d{#2}} % \int{exp}{var}{for all}

\newcommand\T{^{\scriptscriptstyle T}}
\renewcommand\H{^{\scriptscriptstyle H}}

\renewcommand\vec[1]{\boldsymbol{#1}}
\newcommand\mat[1]{\boldsymbol{#1}}

 
\newcommand\I{\mat I}
\renewcommand*\a{\vec a}
\renewcommand*\i{\vec i}
\renewcommand*\k{\vec k}
\newcommand*\n{\vec n}
\newcommand*\p{\vec p}
\newcommand*\s{\vec s}
\newcommand*\w{\vec w}
\newcommand*\x{\vec x}
\newcommand*\y{\vec y}

\newcommand*\A{\mat A}
\newcommand*\B{\mat B}
\newcommand*\C{\mat C}
\newcommand*\E{\mat E}
% \renewcommand*\H{\mat H}
\renewcommand*\P{\mat P}
\newcommand*\eP{\mat{\hat P}}
\newcommand*\R{\mat R}
\newcommand*\Ri{\R^{-1}}
\newcommand*\eR{\mat{\hat R}}
\newcommand*\eRi{\hat{\mat R}\,\!^{-1}}
\newcommand*\Navg{N_\text{avg}}
\newcommand*\W{\mat W}
\newcommand*\X{\mat X}
\newcommand*\Xd{\X_{\!\Delta}}
\newcommand*\Y{\mat Y}
\renewcommand*\B{\mat B}

\renewcommand*\L{\mat \Lambda}
\newcommand*\U{\mat U}
% \renewcommand*\t{\mathtiny{^T}}
% \newcommand*\h{\mathtiny{^H}}
\renewcommand*\t{^T}
\newcommand*\h{^H}

\newcommand\D{\vec\nabla} %Del: Vector differential operator - nabla
\newcommand\Dx{\vec\nabla\times}
\newcommand\Dd{\vec\nabla\cdot}

\usepackage{tikz}
\usetikzlibrary{shapes,snakes}
\usepackage{amsmath,amssymb}
% \usepackage{glossaries}

\newcommand\graphicsAI[2][]{%
  \immediate\write18{./bin/laFigure #2 #1}%
  \input{result}}%

\definecolor{tabBlue}{HTML}{AACCFF}


\newenvironment{outline}
{\begin{itemize}}
{\end{itemize}}


\begin{document}
% \setlength{\headrulewidth}{0.0pt}

%~~ TitlePage ~~%                               %~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~%
\thispagestyle{empty}
\pagenumbering{arabic} %Normal numbers

{\Large\bf Adapting the MVDR beamformer to a GPU for differently sized active sonar imaging systems.}

\begin{abstract}
The MVDR beamformer has been shown to improve active sonar image quality compared to conventional methods. Unfortunately, it is also significantly more computationally expensive because a spatial covariance matrix must be estimated and inverted for each image pixel. We target this challenge by altering and mapping the MVDR beamformer to a GPU, and suggest three different solutions depending on the system size.

For systems with relatively few channels, we suggest arithmetic optimizations for the estimation step, and show how a GPU can be used to yield image creation rates of more than 1\,Mpx/s. For larger systems we show that frequency domain processing is preferable, as this promotes high processing rates at a negligible reduction in image quality. These GPU implementations consistently reduced the runtime by 2-3 orders of magnitude compared to our reference C and Matlab implementations.

For even larger systems we suggest employing the LCA beamformer. It does not calculate a weightset, but merely computes the beamformer output for each of a predefined set of weights, and selects the one that best fulfils the MVDR criterion. The LCA creates images with a quality comparable to MVDR, and it is perfectly suited for a GPU.
\end{abstract}
\vspace{2cm}
(Forsiden genereres av ASA.)
% \ \\
% Total: 195 words (200 max)
% 
% \ \\
% Noen tanker jeg har selv naa:
% \begin{itemize}
% \item Det mangler noe om bruksomraader.
% \item Maa passe paa aa ikke selge LCA saa bra at MVDR ser helt haaplos ut(?)
% \end{itemize}
% 
% 
% \ \\
% Questions they wanted answered:
% \begin{itemize}
% \item This session will feature work on adapting computationally demanding modeling and signal processing tasks to take advantage of various parallel architectures, such as cloud computing, computing clusters, multicore CPUs, multi-core graphic processing units (GPUs), DSP chips, and FPGAs.
% \item If algorithm is slow - What technology will help me?
% \item What skills are needed?
% \item What tools are available and what's the cost?
% \item What acceleration factor are we looking at?
% \item How can I get started?
% \item What we did. Which tools? Was it hard? Speedup?
% \end{itemize}

\newpage
\section{Introduction}

Graphics Processing Units (GPUs) is a technology tailored to perform image processing as fast as possible. They are available off-the-shelf at reasonable prices, are very power efficient, and can be programmed to carry out a wide range of computational tasks, often displaying speed increases of an order of magnitude compared to similar CPU designs. Initially, GPUs may seem perfectly suited for image reconstruction algorithms, because usually each pixel can be computed independently and concurrently of one another. While this is true for simple techniques such as conventional beamformers, the more complex per-pixel computations present in adaptive techniques are harder for the GPU to handle.

Through a case study of on such technique, the Minimum Variance Distortionless Response (MVDR) beamformer, we identify these challenges and explain how they were overcome. The MVDR technique is known for its notable potential for improving image quality over simple conventional methods, but it is also far more computationally complex. This is because a spatial covariance matrix must be estimated and inverted for each image pixel, the former dominating for systems with less than 20-30 channels, and the latter otherwise. 

We propose three different solutions to the complexity issue depending on system size. For smaller systems we use the standard time-domain MVDR method, arithmetically optimize the estimation step, and show that image creation rates of more than 1\,Mpx/s can be achieved when this algorithm is run on a GPU. For medium sized systems we suggest applying the MVDR in the beamspace (frequency domain) instead, which allows for comparable processing rates at a negligible reduction in image quality. Finally, for large systems the estimation and inversion step can be avoided completely by utilising the Low Complexity Adaptive (LCA) beamformer.\todo{disse tre første avsnittene burde sikkert vært kortet ned mye men...}
% 
% 
% The end design is more than 2 orders of magnitude faster than a C implementation we started off with, it took considerable effort to get there.
% \\
% << MOTIVATION >>
% \\

Related work can be found e.g. in ultrasound imaging, where Chen et. al have investigated porting a time domain MVDR method to a GPU \cite{Chen2009,Chen2011,Chen2011a}. Unlike their work, however, we do not impose the restriction of the input data to be real, nor do we approach larger systems by enforcing Toeplitz structure of the covariance matrix. 
% \\

This article is outlined as follows: First we will present the mathematical formulation and evaluate complexity aspects of the MVDR method operated in time or frequency domain, and on the LCA beamformer. Then we mention some of our experiences with implementing the MVDR on a GPU, before concluding with some results and final thoughts.


\section{Methods}\label{methods}

Suppose that a backscattered wavefield is recorded by an $M$ element uniform linear array, that a suitable set of delays are applied to the channels for the pixel of interest, and let the delayed output from the $m$'th channel be given as $x_m$. By definition a beamformer's output $z[n]$ at time instant $n$ is a weighted sum all the delayed data outputs:
\begin{align}
z[n] = \w\H[n]\x[n] = \bmat{w_0[n]\\w_1[n]\\\vdots\\w_{M-1}[n]}^H \bmat{x_0[n]\\x_1[n]\\\vdots\\x_{M-1}[n]},\label{z}
\end{align}
where $w_m$ is the weight factor assigned to channel $m$. With static weights this would be referred to as the conventional delay-and-sum (DAS) beamformer. Various weighting patterns exists here for trading lateral resolution for improved noise suppression (contrast), but one always ends up with a compromise between the two\todo{don't quite like this one}~\cite{Harris1978}. However, there exists a class of adaptive beamformers that target this limitation by adapting the weights to the impinging wavefield. The MVDR method is one such technique.

\subsection{MVDR beamforming in the time domain}

\begin{figure}[t]\centering%
\graphicsAI[drawing,width=0.7\linewidth]{gfx/implementation.svg}%
\caption{MVDR beamforming. For one of the total number of pixels in range and azimuth, $N_y$ and $N_x$,\newline
1. an $L\times{}L$ sample covariance matrix $\eR$ is computed, \newline
2. the term $\eR^{-1}\1$ is found using a linear equation solver,\newline
3. and the beamformer output is computed from $z$ from (\ref{finalZ}), where $\w$ is found by substituting $\eR^{-1}\1$ into (\ref{weights}). }\label{mvdr_beamforming}
\end{figure}
The basic idea behind the MVDR method is to compute the set of weights that minimizes the noise and signal power accumulated by the array, but with the constraint of unity gain for signals coming from the pixel of interest. When the data is delayed this can be formulated as follows:
\begin{gather}
\argmin{\w}\ E\Big\{\big|\w\H[n]\x[n]\big|^2\Big\} \qquad\text{subject to}\qquad \w\H[n]\1 = 1. \label{mvdr_def}
% \vec w[n] = \frac{\Ri[n]\1}{\1\T\Ri[n]\1},\label{weights}
\end{gather}
This is a convex optimization problem with the solution:
\begin{gather}
\vec w[n] = \frac{\Ri[n]\1}{\1\T\Ri[n]\1},\label{weights}
\end{gather}
where $\1$ is a row vector of ones that represents broadside steering, and $\R=E\{\x[n]\x\H[n]\}$ is the spatial covariance matrix for the full array. Since $\R$ is unknown, we estimate it by by computing a sample covariance matrix $\eR$. In this computation we perform some degree of \emph{spatial averaging} to avoid signal cancellation, \emph{temporal averaging} to maintain true speckle statistics, and \emph{diagonal loading} to improve robustness to parameter errors ~\cite{Synnevag2009a}. Combined, these techniques will also ensure a numerically well conditioned $\eR$. 

To arrive at a formulation of how $\eR$ can be estimated, we first split the array into subarrays of length $L$ that overlap on all but one sensor. If we let $x_l[n]$ represent the datavector from subarray $l$,
\begin{gather}
\x_l[n] = \bmat{x_l[n] & x_{l+1}[n] & \dots & x_{l+L-1}[n]}\T.
\end{gather}
then the sample covariance matrix formed with temporal and spatial averaging, $\eR$, is given as:
\begin{gather}
\eR[n] =  \frac{1}{N_K N_L} \sumb{l=0}{N_L-1}\sumb{n'=n-K}{n+K} \x_l[n]\x_l\H[n] \in\mathbb{C}^{L,L},\label{spatialR}
\end{gather}
where $N_K = 2K+1$ is the number of temporal samples to perform averaging over, and $N_L = M-L+1$ is the number of subarrays. In the actual design a fraction of the total power of $\eR[n]$ is finally added to its diagonal~\cite{Synnevag2007}, but this step will be ignored here due to its negligible contribution to runtime.

To summarize as in Figure \ref{mvdr_beamforming}: For every pixel in the image we estimate $\eR$ (\ref{spatialR}), solve the linear equation $\eRi\1$ (\ref{weights}), the finally substitute some to get the beamformer output (\ref{mvdr_def}-\ref{weights}).


\subsubsection{Complexity and implementation}

If (\ref{spatialR}) were to be implemented directly, we note that the estimation step would have a complexity of O($N_K N_L L^2$). By comparison, performing a Gauss Jordan inversion is generally of O($L^3$), which implies that whenever $N_K\,N_L = N_K(M-L+1) \gg L$ the estimation step will dominate. This tends to be true in active systems because we often want to set $L<M/2$ and $N_K\ge>3$ for the MVDR to be robust enough to yield the expected results.

A few properties let us improve these matters notably. First, we may infer from (\ref{spatialR}) that:
\begin{itemize}
\item The subarray covariance matrices $R_l[n] = \x_l[n]\x_l\H[n]$ are Hermitian semi-definite, which means that we can get away with computing only one of their triagonals.
\item When summing $R_l[n]$ most of the multiplications need only be computed only once, and most sums can be updated iteratively.
\end{itemize}
Second, each of the diagonals of $R_l[n]\ \forall\ l$ can be computed independently, which is good news for our GPU design.

\subsection{MVDR beamforming in the frequency domain}

As we increase system size the inversion step will take over as the main bottleneck. We can, however, reduce the dimensionality further than subarray averaging already has by performing MVDR beamforming in the frequency domain. The underlying concept here that for narrowband data there will be a direct relation between the Fourier transform across the array and angles of arrival in the spatial domain; the zero-frequency will correspond to broadside, and increasing frequencies will map to monotonously increasing opening angles. Since the combined transmit and receive response is highly directive, this method allows us to only process the angles where our signals are coming from~\cite{Nilsen2009a,VanTrees2002}. The method is called beamspace MVDR.

The beamspace MVDR formulation very closely resembles that of the time domain MVDR. The main difference is the initial need to Fourier transform the data:
\begin{gather}
\x_{\text{BS},l}[n] = \B\x_l[n], \qquad \B\in \mathbb{C}^{N_b,L}, \qquad \text{where} \qquad [\B]_{p,q} = \frac{1}{\sqrt{L}} e^{-j2\pi\,p\,q/L}.\label{beamspace}
\end{gather}
Here $\B$ is referred to as the Butler matrix, $l$ is the subarray index, and $N_b$ is the number of beams that should be computed. Note has once $\x_{\text{BS},l}[n]$ is computed, $\eR_\text{BS}$ can be found as in (\ref{spatialR}), $\w_\text{BS}$ as in (\ref{weights}), and $z$ as in (\ref{z}).

When we reduce the covariance size from $L$ to $N_b$ we also reduce the estimation step to O($N_K N_L N_b^2$), and the inversion step to O($N_b^3$). The downside is the additional computations required by the frequency transform, which must be weighted up against the gain of reducing $N_b$.

\subsection{LCA beamformer}

The Low Complexity Adaptive (LCA) beamformer is another take on the optimization problem in (\ref{mvdr_def}). Instead of calculating the weights like in (\ref{weights}), it simply computes the beamformer output for each window in a larger set of windows, and finally applies the one that best fulfils the given optimization criterion. If we let $\w_p$ be the $p$'th of a total of $P$ windows, then this can be formulated as~\cite{Synnevag2008}:
\begin{gather}
\argmin{p}\ E\Big\{\big|\w_p\H\x[n]\big|^2\Big\} \qquad\text{subject to}\qquad \w_p\H\1 = 1. \label{lca_def}
\end{gather}
Note the similarity between (\ref{mvdr_def}) and (\ref{lca_def}). The LCA and MVDR uses essentially the same optimization criterion, but whereas MVDR searches a continuous solution space for the best set of weights to apply, the LCA beamformer only have $P$ solutions to select from. However, we have found that once the LCA has 10-20 well designed windows available the quality of the images it produces quickly approaches that of the MVDR beamformer.

Although LCA promotes good image quality, its two most attractive traits is perhaps its simplicity and low computational complexity. The LCA is essentially a delay-and-sum (DAS) beamformer where the delay step is carried out as usual, but where the weighting and summing is repeated for each of the $P$ windows. In its basic form its computational complexity only of O($M\,P$).


\section{Implementation}\label{implementation}

\begin{figure}[t]\centering%
\graphicsAI[drawing,width=\linewidth]{gfx/mvdr_implementation.svg}%
\caption{MVDR implementation.}\label{mvdr_implementation}
\end{figure}

Our GPU implementation consists of three main kernels, one for each of the computing steps illustrated in Figure \ref{mvdr_implementation}. In the first step we estimate $\eR$, in the second we solve the linear equation $\eRi\1$, and finally we perform some substitutions to obtain the beamformer output, $z$. All pixels are processed by one step before we move on to the next step. Our efforts here were mainly focused on estimating $\eR$, because a highly optimised batch linear equation solver is already available from Nvidia, and computing the beamformer output is a rather simple task.

When computing $\eR$ we we assign $L$ threads per pixel to traverse the diagonals of $\eR$. On the top row a full computation is carried out, then that entire row is saved back to global memory following a collective access pattern that maximizes global memory bandwidth. For subsequent rows the threads move along the diagonals while performing iterative summations; the result from the previous element on the diagonal is updated by adding and removing the correlation coefficients that enters and exits the sum, respectively. To minimize memory consumption, we compute the coefficients again every time we need them. When a thread has finished up a diagonal, we have them wrap around to compute one of the diagonals in the lower triangular of $\eR$. Since $\eR$ is conjugate symmetric, the values in the leftmost column is obtained by a complex conjugate copy of the relevant value in the first row. This procedure balances the load evenly on all threads, is almost completely free of arithmetic redundancy, and consumes very little memory.

The implementation of beamspace MVDR is very similar, but the data access pattern is different. In the time domain subsequent subarrays overlap on all but one element in memory, but the Fourier transformed data does not overlap at all. Such a seemingly innocent detail can make all the difference in a GPU design, because designing to make efficient use of memory is key to obtaining good performance.



% These challenges are very closely linked. The Quadro 6000 architecture is of compute capability 2.0, which means there are 48\,kB of shared memory (L1 cache) and 128\,kB of registers per SM~\cite{Nvidia2012}. This memory is shared by all active threads on that SM, a number that should be no less than 768~\cite{Nvidia2012a}. This will expose a sufficient level of data parallelism to ensure that memory latency is completely hidden (Little's law). By dividing the shared memory evenly on all 768 threads we find that each thread should store no more than 8 single precision complex numbers in shared memory\todo{introduce memory structure -shared for data shared between threads}, and 24 stored in registers. This should make it apparent why computing a single pixel per thread is a bad idea, and why we need to keep each thread as light on memory consumption as possible.

% Most of the challenges we faced when porting the MVDR to a GPU are caused by a single troublesome fact: GPU prefers threads that computationally intensive but very light on memory consumption. 



% The solution is make sure that each thread primarily access the shared memory (L1 cache) and registers. Unfortunately, these are scarce resources and 


\section{Results}


To display the imaging capabilities of the mentioned beamformers, we have processed experimental datasets from the 32 element Kongsberg Maritime HISAS1030 sonar mounted on the HUGIN AUV~\cite{Hansen2009}. HISAS1030 is a high resolution synthetic aperture sonar with an array length of 1.2\,m and operating frequency of 100\,kHz, and it was operated in sidescan mode here. The studied object is the 1500 dwt oil tanker wreck Holmengraa. It is 68\,m long and 9\,m wide, and lies at a slanted seabed at 77\,m depth outside of Horten, Norway. The results are shown in Figure \ref{holmengraa}. The MVDR images were processed with parameters $L$=16, $K$=3, and 1\% diagonal loading. For beamspace MVDR we set $N_b=L/2$. LCA was designed with a window database consisting of 5 Kaiser windows, each with different window-parameters from the range $\beta\in[0,10]$, and each steered in 5 distinct directions leaving a total of 25 windows for the LCA to select from.

A few benchmarks of these methods are presented in Figure \ref{benchmark}. On our test system with a quad-core Intel Xeon E5620, 64Gb of RAM and an nVidia Quadro 6000 card, the MVDR methods managed to create images at rates just over 1\,Mpx/s. A single-thread C implementation that was added as reference was outperformed by around 2 orders of magnitude. However, do not consider this comparison fair because while the GPU design is make efficient use of the L1 cache, similar optimisation work was not carried out on the CPU design.

\begin{figure}[!t]\centering%
\graphicsAI[drawing,width=\linewidth]{gfx/plot_holmengraa_L16_Navg1.pdf}%
\caption{The 68$\times$9\,m oil tanker Holmengraa lying at a depth of 77\,m. The MVDR images were processed with L=16, K=3, and 1\% diagonal loading. For beamspace MVDR we set $N_b=L/2$. LCA was set up with a window database consisting of 5 Kaiser windows with the window-parameter set in the range $\beta\in[0,10]$, and then each of these were steed in 5 distinct directions leaving a total of 25 windows for the LCA to select from..}\label{holmengraa}
\end{figure}

% \begin{table}[h]\centering%\normalsize
% \begin{tabular}[c]{l r r r@{:}  l}\hline
% \rowcolor{tabBlue} & \multicolumn{1}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{arithmetic}$} & \multicolumn{1}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{memory}$} & \multicolumn{2}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{memory}$/BW$_\text{arithmetic}$} \\\hline
%  & & & & \\
% \end{tabular}
% \caption{Nvidia Quadro 6000; Memory bandwidths (BW) compared to the peak arithmetic bandwidth of 1.03 Tflop/s.}\label{tabbandwidth}
% \end{table}

\begin{figure}[!h]\centering%
\graphicsAI[drawing,width=.8\linewidth]{gfx/benchmark1_tagged.pdf}%
\caption{Benchmarks for the our time-domain and frequency-domain MVDR method running on a GPU. The grey line marks the realtime requirement for the HUGIN AUV to perform full-coverage sectorscan images with a ping rate of 3 pings/s.}\label{benchmark}
\end{figure}


\newpage
\section{Discussion}

% \begin{table}[b]\centering%\normalsize
% \begin{tabular}[c]{l r r r@{:}  l}\hline
% \rowcolor{tabBlue} & \multicolumn{1}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{arithmetic}$} & \multicolumn{1}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{memory}$} & \multicolumn{2}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{memory}$/BW$_\text{arithmetic}$} \\\hline
% Arithmetic throughput & 1.03 Tflop/s & & \hspace{30pt} 1 & 30 \\
% Global memory & & 36 Gfloats/s & \hspace{30pt} 1 & 30 \\
% Shared memory & & 257 Gfloats/s & 1 & 4 \\
% Registers & & $>$1.5 Tfloats/s & $>$3 & 2~\cite{Vasilyy}
% \end{tabular}
% \caption{Nvidia Quadro 6000: Memory bandwidths (BW) compared to the peak arithmetic bandwidth of 1.03 Tflop/s.}\label{tabbandwidth}
% \end{table}


The MVDR beamformer is a technique that is capable of improving image quality over conventional methods. This can be seen in Figure \ref{holmengraa}, where the MVDR produces images with cleaner shadows and slightly improved edge definitions. Contrary to common belief, it is also possible to create these images relatively fast. Through careful optimization work and by running the MVDR on a GPU we have achieved image creation rates of more than 1\,Mpx/s. This is an improvement of 2 orders of magnitude over our reference implementation in C. To obtain these rates we run MVDR in the time-domain for smaller systems, and in the frequency domain for larger systems.

If this performance is insufficient, we suggest looking at the LCA method. It is based on the same optimisation criterion as the MVDR method, but avoids the estimation and inversion step altogether by limiting the weight's solution space to only a few predefined windows. As seen the Figure \ref{holmengraa}, it produces images with a quality comparable to the MVDR method, but computing the images takes only a fraction of the time.



% Finally, throughout our work with porting the MVDR beamformer to a GPU, one challenge has been particularly difficult to solve: The GPU will only perform efficiently when each computing thread is very computationally intense. This should be apparent by studying Table \ref{tabbandwidth}. It compares theoretical peak values for the memory bandwidth and arithmetic throughput for an Nvidia Quadro 6000 GPU. Looking at global memory, we note that it is only able to move 1 float for every 30 floating point operation that the GPU is able to execute. Now, consider the simple equation we the simple equation $C=A+B$, where the ratio is 3 floats read/written for every 1 floating point operation, we realise that global memory should be avoided whenever possible. 


% 
% $\underset{p}{\argmin}$
% 
% \begin{gather}
% \vec w[n] = \frac{\Ri[n]\1}{\1\T\Ri[n]\1},\label{weights}
% \end{gather}




% \begin{figure}[!t]\centering
% \includegraphics[width=\linewidth]{gfx/algorithm_structure.eps}
% \caption{MVDR beamforming. First a spatial covariance matrix is estimated from the delayed data (\ref{spatialR}-\ref{finalR}), then the weights are computed (\ref{weights}) and finally applied to the delayed channel data (\ref{z}).}
% \label{implementation}
% \end{figure}
% As summarized in Fig. \ref{mvdr_beamforming}, the MVDR method is applied to each pixel independently, by
% \begin{enumerate}
% \item computing the sample covariance matrix $\eR$ in (\ref{finalR}),
% \item computing $\eRi\1$ in (\ref{weights}), and
% \item computing the beamformer output $z$ in (\ref{finalZ}).
% \end{enumerate}



% 
% \section{Results}
% 
% \begin{figure}[t]\centering
% \graphicsAI[width=\linewidth]{gfx/implementation.svg}
% \caption{MVDR beamforming. For one of the total number of pixels in range and azimuth, $N_y$ and $N_x$,\newline
% 1. an $L\times{}L$ sample covariance matrix $\eR$ is computed, \newline
% 2. the term $\eR^{-1}\1$ is found using a linear equation solver,\newline
% 3. and the beamformer output is computed from $z$ from (\ref{finalZ}), where $\w$ is found by substituting $\eR^{-1}\1$ into (\ref{weights}). } \label{mvdr_beamforming}
% \end{figure}



% 
% \ \\
% Total: 192 words (200 max)
% 
% \ \\
% Noen tanker jeg har selv naa:
% \begin{itemize}
% \item Det mangler noe om bruksomraader.
% \item Maa passe paa aa ikke selge LCA saa bra at MVDR ser helt haapløs ut(?)
% \item 200 ord er ingenting. :)
% \end{itemize}
% 
% 
% \ \\
% Questions they wanted answered:\cite{Kailath1985}
% \begin{itemize}
% \item This session will feature work on adapting computationally demanding modeling and signal processing tasks to take advantage of various parallel architectures, such as cloud computing, computing clusters, multicore CPUs, multi-core graphic processing units (GPUs), DSP chips, and FPGAs.
% \item If algorithm is slow - What technology will help me?
% \item What skills are needed?
% \item What tools are available and what's the cost?
% \item What acceleration factor are we looking at?
% \item How can I get started?
% \item What we did. Which tools? Was it hard? Speedup?
% \end{itemize}
% \end{abstract}

\bibliographystyle{jasanum}
% \bibliography{../../Library/library}
% \bibliography{library}

% \section{Introduction}

\end{document}

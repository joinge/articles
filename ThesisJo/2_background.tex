%&header
% !TeX root = thesis
%% !TeX root = 1_introduction

\input{subheader}
\endofdump

\ifRootBuild\else
  \input{glossary}
  \makeglossaries
\fi

%\beforeepigraphskip

\begin{document}


\newcommand\chapref[2]{\hyperref[#1]{#2.\ref{#1}}}

\chapter{Background}

{

% \newcommand\mat[1]{\boldsymbol{#1}}
\newcommand\bmat[1]{\begin{bmatrix}#1\end{bmatrix}}
\renewcommand*\eR{\mat{\hat R}}
\renewcommand\1{\vec 1}

\section{Introduction}

% Graphics Processing Units (GPUs) is a technology tailored to perform image processing as fast as possible. They are available off-the-shelf at reasonable prices, are very power efficient, and can be programmed to carry out a wide range of computational tasks, often displaying speed increases of an order of magnitude compared to similar CPU designs. Initially, GPUs may seem perfectly suited for image reconstruction algorithms, because usually each pixel can be computed independently and concurrently of one another. While this is true for simple techniques such as conventional beamformers, the more complex per-pixel computations present in adaptive techniques are harder for the GPU to handle.
% 
% Through a case study of on such technique, the Minimum Variance Distortionless Response (MVDR) beamformer, we identify these challenges and explain how they were overcome. The MVDR technique is known for its notable potential for improving image quality over simple conventional methods, but it is also far more computationally complex. This is because a spatial covariance matrix must be estimated and inverted for each image pixel, the former dominating for systems with less than 20-30 channels, and the latter otherwise. 
% 
% We propose three different solutions to the complexity issue depending on system size. For smaller systems we use the standard time-domain MVDR method, arithmetically optimize the estimation step, and show that image creation rates of more than 1\,Mpx/s can be achieved when this algorithm is run on a GPU. For medium sized systems we suggest applying the MVDR in the beamspace (frequency domain) instead, which allows for comparable processing rates at a negligible reduction in image quality. Finally, for large systems the estimation and inversion step can be avoided completely by utilising the Low Complexity Adaptive (LCA) beamformer.\todo{disse tre første avsnittene burde sikkert vært kortet ned mye men...}
% 
% 
% The end design is more than 2 orders of magnitude faster than a C implementation we started off with, it took considerable effort to get there.
% \\
% << MOTIVATION >>
% \\

% Related work can be found e.g. in ultrasound imaging, where Chen et. al have investigated porting a time domain MVDR method to a GPU \cite{Chen2009,Chen2011,Chen2011a}. Unlike their work, however, we do not impose the restriction of the input data to be real, nor do we approach larger systems by enforcing Toeplitz structure of the covariance matrix. 
% \\
\begin{figure}[tp]
\makebox[\linewidth][c]{%
\graphicsAI[drawing,width=1.3\linewidth]{gfx/article_relation.svg}}
\caption{Method relations. This thesis explores three beamformers reconstructing images from acoustic echoes: element-space MVDR (reference), beam-space MVDR (close approximation) and element-space LCA (educated trial-and-error). Article IV presents background on synthesis of image templates from reconstructed images. }%
\label{2_fig_article_relation}
\end{figure}

\begin{figure}[!t]\centering
\makebox[\linewidth][c]{%
\graphicsAI[width=.7\linewidth]{gfx/geometry.svg}}
\caption{
An array with $M$ sensors has reference frame $\udot{A} \triangleq (\udot{A},\uvec{A})$ attached to it, where $\udot{A}\in\mathbb{A}$ is its absolute position and $\uvec{A}\triangleq\big(\hat{x}_{A},\hat{y}_{A},\hat{z}_{A}\big)\in\mathbb{V}^3$ its absolute orientation (\,$\hat{\cdot}$ denoting unit length). Impinging on the array at angle $\theta$ is a monochromatic plane wave: a single frequency wave from a source $\mathcal{S}$ far away relative to the wavelength and array length (far field). Notation details are presented in 
}%
\label{2_fig_geometry}
\end{figure}


Any wave, regardless of its nature, is governed by a partial differential equation known as the \emph{wave equation}. Its form for a linear, homogeneous (translation-invariant) and isotropic (rotation-invariant) medium is
%
\begin{align}\label{eq_wave_equation}
\nabla^2 f 
 = \frac{1}{c}\frac{\delta^2 f}{\delta t^2},
\end{align}
%\frac{\delta^2 f}{\delta x^2} + \frac{\delta^2 f}{\delta y^2} + \frac{\delta^2 f}{\delta z^2}
%
where $\nabla^2$ is the Laplace operator, $f$ is field strength and $c$ is wave propagation speed. In complex mediums $c$ may depend on signal strength (non-linear), position (non-homogeneous/refractive), angle (anisotropic), frequency (dispersive) or be non-real (lossy). Deep sea is acoustically non-homogeneous due to varying pressure, temperature and salinity, but has negligible dispersion and attenuation. Biological tissue are non-homogeneous, non-linear and lossy. We approximate both cases with (\ref{eq_wave_equation}), because data inaccuracies are inevitable and good for testing algorithmic robustness.

If $f$ represents displacement of a vibrating string, (\ref{eq_wave_equation}) states that the force pulling the string towards equilibrium (right side) is proportional to the string's curvature (left side). In acoustics $f$ represents sound pressure, with SI unit Pascal [Pa = N/m$^2$] or logarithmic unit sound-pressure-level (SPL) [1\,Pa = 94\,$\mathrm{dB}_{\textrm{SPL}}$]. To generalize and simplify, we keep our equations free of physical units and simply think of $f$ as a signal: a unit-less scalar function with wave characteristics.

The linear homogeneous wave equation has a few solutions of interest, in particular that of a plane and spherical wave. For a field emitted from source position $\udot{S}$ and observed from $m$th sensor position $\udot{m}$, the solutions are
%
\begin{align}
f_\textrm{plane}(t,\vec{p}_{mS})  &= A e^{j(\omega t - \vec{k} \cdot \vec{p}_{mS})} \\
f_\textrm{spheric}(t,\vec{p}_{mS}) &= \frac{A}{\lVert \vec{p}_{mS} \rVert} e^{j(\omega t - \lVert\vec{k}\rVert \lVert \vec{p}_{mS} \rVert)},
\end{align}
% 
where $A$ is amplitude, $\omega$ is temporal wave frequency, $t$ is time, $\lVert\vec{k}\rVert=\frac{\omega}{c}=\frac{2\pi}{\lambda}$ is spatial wave frequency (wavenumber) and $\vec{p}_{mS}$ is position vector $\udot{m}$ to $\udot{S}$. We model the wavefield as superimposed plane waves under far-field conditions (when distance to the source is large relative to wavelength and array length) and as superimposed spherical waves under near-field conditions. 

% One is that of plane wave and the other a  A signal source with the position $\udot{S}$ . We can represent the field observed at $\udot{A}$ as $f(\dvec{p}^A,t)$, where position is represented by $\dvec{p}^A=[x_A,y_A,z_A]^T\in\mathbb{R}^3$ and time by $t\in\mathbb{R}$,
% 
% An introduction to such notation can be found in \chapref{IV_methods}{IV}.
% 
% 
% reference frame $\ubar{A} \triangleq (\udot{A},\uvec{A})$ to it, where $\udot{A}\in\mathbb{A}$ is its absolute position and $\uvec{A}\triangleq\big(\hat{x}_{A},\hat{y}_{A},\hat{z}_{A}\big)\in\mathbb{V}^3$ its absolute orientation (where $\hat{\cdot}$ denotes unit length)


%

%
% \hyperref[IV_methods]{\chapterref{IV_methods}.\sectionref{IV_methods}}
% \renewcommand{\thesection}{\thechapter.\arabic{section}}

% Suppose an array of sensors has a reference frame $\ubar{A} \triangleq (\udot{A},\uvec{A})$ attached to it, where $\udot{A}\in\mathbb{A}$ is its absolute position and $\uvec{A}\triangleq\big(\hat{x}_{A},\hat{y}_{A},\hat{z}_{A}\big)\in\mathbb{V}^3$ its absolute orientation (where $\hat{\cdot}$ denotes unit length). 


% This article is outlined as follows: First we will present the mathematical formulation and evaluate complexity aspects of the MVDR method operated in time or frequency domain, and on the LCA beamformer. Then we mention some of our experiences with implementing the MVDR on a GPU, before concluding with some results and final thoughts.


\section{Image reconstruction}\label{methods}

Consider an acoustic signal transmitted to highlight a surface of interest. Assume the backscattered wavefield is properly sampled using a uniform linear array (ULA) of receivers, stripped of its carrier frequency by heterodyning and its signal signature by matched filtering (Fig. \ref{2_fig_article_relation}). Further assume the sensors are linear, infinite bandwidth and invarant to shifts in position (homogeneous, inter-independent), direction (isotropic) and time. Image reconstruction coherently combines these receiver outputs to focus at an angle or point at a time. Configuring the array's focus in range and direction is commonly referred to as beamforming, and involves assigning suitable delays and weights to the array's channels.


\subsection{Beamforming}
% \ifPhdDoc
% \begin{figure}[htbp]\centering
% \includegraphics[width=\linewidth]{gfx/buske1\figPostfix.eps}
% \else
% \ifPeerReview
% \begin{figure}[htbp]\centering
% \includegraphics[width=0.8\linewidth]{gfx/buske1\figPostfix.eps}
% \else
% \begin{figure}[!t]\centering
% \includegraphics[width=\linewidth]{gfx/beamforming.eps}
% \fi\fi%
% \caption{Beamforming principle. Signal signature is first removed by matched filtering. Then, before summation, a suitable set of delays $\Delta$ and weights $w$ are applied to focus on a pixel of interest at angle and range ($\theta,n$).}\label{I_beamforming}
% \end{figure}

\begin{figure}[tp]
\makebox[\linewidth][c]{%
\graphicsAI[width=1\linewidth]{gfx/scenario_interference_das.svg}}
\caption{DAS (delay-and-sum) beam pattern is static (conventional beamforming). Interference suppression at the first mainlobe is -13\,dBr.}%
\label{2_fig_scenario_das}
\end{figure}

\begin{figure}[tp]
\makebox[\linewidth][c]{%
\graphicsAI[width=1\linewidth]{gfx/scenario_interference_mvdr.svg}}
\caption{MVDR (minimum variance distortionless response) beam pattern is dynamic and continuous (adaptive beamforming). Interference suppression is good for prevalent noise sources assuming sufficient spatial statistics and enough unconsumed degrees of freedom (i.e. enough sensors to cancel the prevalent noise sources).}%
\label{2_fig_scenario_mvdr}
\end{figure}

\begin{figure}[tp]
\makebox[\linewidth][c]{%
\graphicsAI[width=1\linewidth]{gfx/scenario_interference_lca.svg}}
\caption{LCA (low complexity adaptive) beam pattern is dynamic and discrete (adaptive beamforming). Interference suppression is on-par with MVDR with 15 weight sets to choose from, marginally worse with 6 weight sets.}%
\label{2_fig_scenario_lca}
\end{figure}

Let the array have $M$ sensors equally spaced at positions $\udot{0},\udot{1},\dots, \udot{m}, \dots, \udot{M{\!-\!1}}$ with reference frame $\ubar{A} \triangleq (\udot{A},\uvec{A})$ attached to its phase center (Figure \ref{2_fig_geometry}), where $\udot{A}\in\mathbb{A}$ is its absolute position and $\uvec{A}\triangleq\big(\hat{x}_{A},\hat{y}_{A},\hat{z}_{A}\big)\in\mathbb{V}^3$ its absolute orientation ( $\hat{\cdot}$ denoting unit length). Data sample $n$ from channel $m$ delayed by $\Delta_m$ is written $x_m[n-\Delta_{m}, \vec{p}_{Am}]\in\mathbb{C}$. The delays (normalized by sampling frequency $f_s$) coarsely aligns signals from source $\udot{S}$,
%
\begin{align}
\Delta_m[n] = \frac{\lVert \vec{p}_{mS}\rVert - \underset{m'}{\mathrm{min}}\ \lVert \vec{p}_{m'S}\rVert}{c\,f_s},\label{2_eq_delta}
\end{align}
%
where both $\vec{p}_{mS}$ and $\vec{p}_{m'S}$ denote position vector $\udot{m}$ to $\udot{S}$. Subtracting the minimum distance is mathematically optional, but facilitates physical realization and low latency. By assuming implicit dependence on $\vec{p}$ and data pre-delayed to the pixel of interest, we simplify notation to $x_m[n]\in\mathbb{C}$. Beamformer output $z[n]\in\mathbb{C}$ is, by definition, the weighted sum of delayed data samples,
%
\begin{align}
z[n] = \dvec{w}^H[n]\dvec{x}[n] = \bmat{w_0[n]\\w_1[n]\\\vdots\\w_{M-1}[n]}^H \bmat{x_0[n]\\x_1[n]\\\vdots\\x_{M-1}[n]} \in\mathbb{C},\label{2_eq_z}
\end{align}
%
where the weights are normalized and $w_m=\in\mathbb{C}$ is the weight factor assigned to channel $m$. The weights are normalized, $\dvec{w}^H\dvec{1}=1$, Spatial responses of the weights for an array steered to broadside are characterized by the beam pattern,
%
\begin{align}
W(\vec{k}) = \sum_m^{M-1} w_m^* e^{j\vec k \cdot \vec{p}_{Am}},\label{2_eq_beam pattern}
\end{align}
%. Beampattern is broadside-steered beamformer output in the presence of a single plane wave, as a function of the wave's angle.
%%Steered response is beamformer's output in the presence of some wave field, as a function of steering angle. 
%
where the start position $\udot{A}$ is arbitrary. Note how the beam pattern depends on both angle and frequency of the incoming wave. 

The beamformer is called delay-and-sum (DAS) or conventional if the weights are static (temporally non-varying). Various weighting functions exist for trading lateral resolution for improved noise suppression (contrast), but a compromise between the two is unavoidable~\cite{Harris1978}. A class of adaptive beamformers target this limitation by adapting the weights to the dynamic impinging wavefield. One such technique is the minimum variance distortionless response (MVDR) or Capon beamformer, named after its maker for use in spectral estimation~\cite{Capon1969}. We discuss two versions of it termed by 

% Assume:
% Known array characteristics (sensor locations, element patterns, ...
% Stationary signal and noise
% Long observation times
% Known direction of arrival


% MVDR

% MPDR 

% Applications: Radar, radar astronomy, sonar, commnications, direction finding, seismology, tomography, 

% Performance measures
% Array: Directivity, array gain vs spatially white noise, sensitivity or tolerance factor, 


\subsection{Element-space MVDR}

%\begin{figure}[t]\centering%
%\graphicsAI[drawing,width=1\linewidth]{gfx/implementation.svg}%
%\caption{MVDR beamforming. For one of the total number of pixels in range and azimuth, $N_y$ and $N_x$,\newline
%1. an $L\times{}L$ sample covariance matrix $\eR$ is computed, \newline
%2. the term $\eR^{-1}\1$ is found using a linear equation solver,\newline
%3. and the beamformer output is computed from $z$ from (\ref{finalZ}), where $\w$ is found by substituting $\eR^{-1}\1$ into (\ref{2_eq_weights}). }\label{mvdr_beamforming}
%\end{figure}
%

Element-space (time-domain) MVDR often improves image contrast and resolution compared to conventional beamformers~\cite{Benitz1997,Synnevag2007,Blomberg2013,Blomberg2012a,Dursun2009,Lo2004}, but is computationally complex and statistically fragile (more on this later). It computes the weights that minimize noise and interference accumulated by the array, while enforcing unit gain for signals from the pixel of interest,
%
\begin{gather}
\argmin{\dvec{w}}\ E\Big\{\big|\dvec{w}^H[n]\dvec{x}[n]\big|^2\Big\} \qquad\text{subject to}\qquad \dvec{w}^H[n]\dvec{a} = 1, \label{2_eq_mvdr_def}
% \vec w[n] = \frac{\Ri[n]\1}{\1^T\Ri[n]\1},\label{2_eq_weights}
\end{gather}
%
where $\dvec{a}$ is steering vector. Solving this convex optimization problem with Lagrange multipliers yields
%
\begin{gather}
\dvec w[n] = \frac{\Ri[n]\dvec{a}}{\dvec{a}^T\Ri[n]\dvec{a}}, \label{2_eq_weights}
\end{gather}
%
where $\dvec{a}=\dvec{1}$ is a row-vector of ones representing broadside phase-steering and $\R=E\{\dvec{x}[n]\dvec{x}^H[n]\}$ is the spatial covariance matrix for the full array. In the presence of zero-mean random Gaussian noise, these weights yield the maximum likelihood estimate of the signal and the maximum signal-to-interference-and-noise ratio (SINR). However, active systems or passive ones subjected to multipath or jamming, experience highly correlated noise, interference and signal~\cite{Widrow1982}. Limited amount of data, array miscalibration and model inaccuracies makes matters worse, sometimes resulting in performance inferior to DAS~\cite{Li2006robust}. 

To make MVDR robust, it must avoid signal cancellation, preserve speckle statistics and ensure numerical and statistical robustness. Literature suggests estimating $\R$ with a sample covariance matrix $\eR$ using some degree of
%
\begin{itemize}
\item \emph{Spatial smoothing}: Decorrelates coherent echoes to avoid signal cancellation, assuming regular arrays. We achieve this through subarray averaging~\cite{Kailath1985}, which trades off spatial resolution and makes the covariance matrix exhibit Toeplitz-like structure. Some studies construct inversion-friendly Toeplitz-matrices directly [TK87]. $\eR$ is guaranteed non-singular in cases with twice as many subarrays as signals [WPMS88,PK89]. 
\item \emph{Temporal smoothing} over an interval comparable to the pulse length (one to five samples) to maintain true speckle statistics~\cite{Synnevag2009};
\item \emph{Diagonal loading} to improve robustness to parameter errors~\cite{Cox1987,Maksym1979,VanTrees2002}.
\end{itemize}%
%
These techniques ensure a numerically well conditioned $\eR$, allow reducing the computational complexity and expose enough data parallelism to facilitate GPU-acceleration. 


Topeplitz [TK87] - choose wm to make the smoothed matrix close to Toeplitz. Topelitz weighting, adaptive spatial averaging in literature. [TK87]

Formulation of the sample covariance matrix $\eR$ begins by splitting the array into subarrays of length $L$ that overlap on all but one sensor. If we let $x_l[n]$ represent the datavector from subarray $l$,
%
\begin{gather}
\dvec{x}_l[n] = \bmat{x_l[n] & x_{l+1}[n] & \dots & x_{l+L-1}[n]}^T,
\end{gather}
%
then $\eR$ formed with temporal and spatial averaging (smoothing) is given as
%
\begin{gather}
\eR[n] =  \frac{1}{N_K N_L} \sumb{l=0}{N_L-1}\sumb{n'=n-K}{n+K} \x_l[n]\x_l^H[n] \in\mathbb{C}^{L,L},\label{2_eq_spatialR}
\end{gather}
%
where $N_K = 2K+1$ is the number of temporal samples to perform averaging over, and $N_L = M-L+1$ is the number of subarrays. A fraction of the total power of $\eR[n]$ is finally added to its diagonal~\cite{Synnevag2007}.

To summarize as in Figure \ref{mvdr_beamforming}: For every pixel in the image we estimate $\eR$ (\ref{2_eq_spatialR}), solve the linear equation $\eRi\1$ (\ref{2_eq_weights}), the finally substitute some to get the beamformer output (\ref{2_eq_mvdr_def}-\ref{2_eq_weights}).




\subsection{Beam-space MVDR}

Systems with narrow beams, narrow bands, or both, have most backscattered energy residing in center spatial frequencies. Zero-frequency maps to broadside, higher frequencies map to larger opening angles. Computing weighted combinations of such frequencies, similarly to doing so with elements, is referred to as beamspace or discrete Fourier-transform (DFT) beamforming. 

%,  Similarly to performing weighted sums of elements, we perform weighted sums of frequencies  Weighted sums of Performing weighted sum 

In imaging sonar and ultrasound systems, the combined transmit and receive response is usually narrow enough to contain most energy in three or five center beams~\cite{Nilsen2009a,VanTrees2002}. Above 32 channels the inversion step becomes a greater computational bottleneck than covariance estimation. We mitigate this by applying space reduction in the spatial frequency-domain, or beamspace. 

Beam-space MVDR resembles element-space MVDR, but demands an initial Fourier transformation of the data:
%
\begin{gather}
\x_{\text{BS},l}[n] = \mat{B}\x_l[n], \qquad \mat{B}\in \mathbb{C}^{N_b,L},\label{2_eq_beamspace}
\end{gather}
%
where $l$ is subarray index, $N_b$ is number of beams that should be computed and
%
\begin{gather}
[\mat{B}]_{p,q} = \frac{1}{\sqrt{L}} e^{-j2\pi\,p\,q/L}.\label{2_eq_butler}
\end{gather}
%
is the Butler (or DFT) matrix~\cite{Butler1961}. Once $\x_{\text{BS},l}[n]$ is computed, $\eR_\text{BS}$ can be found as in (\ref{2_eq_spatialR}), $\w_\text{BS}$ as in (\ref{2_eq_weights}), and $z$ as in (\ref{z}).

Reducing $\eR_\text{BS}$ size from $L$ to $N_b$ reduce estimation to O($N_K N_L N_b^2$), and the inversion step to O($N_b^3$). The downside is the additional computations required by the frequency transform, which must be weighted up against the gain of reducing $N_b$.



\subsection{LCA beamformer}

The Low Complexity Adaptive (LCA) beamformer offers a different approach to the optimization problem in (\ref{2_eq_mvdr_def}). Instead of calculating weights like MVDR in (\ref{2_eq_weights}), it iterates through a set of precomputed weights and applies the one that best fulfils the optimization criterion. If $\w_p$ denotes the $p$'th out of $P$ weight sets, then LCA can be formulated as~\cite{Synnevag2008}:
%
\begin{gather}
\argmin{p}\ E\Big\{\big|\w_p^H\x[n]\big|^2\Big\} \qquad\text{subject to}\qquad \w_p^H\1 = 1. \label{2_eq_lca_def}
\end{gather}
%
Note the similarity between (\ref{2_eq_mvdr_def}) and (\ref{2_eq_lca_def}). Both LCA and MVDR rely on the same optimization criterion, but whereas MVDR searches a continuous solution space for the optimal weights, LCA only have $P$ solutions to select from.



\section{Image synthesis}

\subsection{Template matching}
 
Template matching classifies objects by comparing them to idealized image templates of relevant objects and orientations, and assigning the most similar class. Similarity metrics like sum of absolute differences (SMD) and normalized cross-correlation (NCC) yield good results in computer vision~\cite{Brunelli2009}, but not in sonar imaging---likely due to noise~\cite{Myers2007}. 


To improve noise- In sonar imaging Several adaptiations to sonar imaging approaches 


% These challenges are very closely linked. The Quadro 6000 architecture is of compute capability 2.0, which means there are 48\,kB of shared memory (L1 cache) and 128\,kB of registers per SM~\cite{Nvidia2012}. This memory is shared by all active threads on that SM, a number that should be no less than 768~\cite{Nvidia2012a}. This will expose a sufficient level of data parallelism to ensure that memory latency is completely hidden (Little's law). By dividing the shared memory evenly on all 768 threads we find that each thread should store no more than 8 single precision complex numbers in shared memory\todo{introduce memory structure -shared for data shared between threads}, and 24 stored in registers. This should make it apparent why computing a single pixel per thread is a bad idea, and why we need to keep each thread as light on memory consumption as possible.

% Most of the challenges we faced when porting the MVDR to a GPU are caused by a single troublesome fact: GPU prefers threads that computationally intensive but very light on memory consumption. 



% The solution is make sure that each thread primarily access the shared memory (L1 cache) and registers. Unfortunately, these are scarce resources and 

% \begin{figure}[!t]\centering\label{2_fig_holmengraa}%
% \graphicsAI[drawing,width=\linewidth]{gfx/plot_holmengraa_L16_Navg1.pdf}%
% \caption{The 68$\times$9\,m oil tanker Holmengraa lying at a depth of 77\,m. The MVDR images were processed with L=16, K=3, and 1\% diagonal loading. For beamspace MVDR we set $N_b=L/2$. LCA was set up with a window database consisting of 5 Kaiser windows with the window-parameter set in the range $\beta\in[0,10]$, and then each of these were steed in 5 distinct directions leaving a total of 25 windows for the LCA to select from..}
% \end{figure}
% 
% \begin{figure}[!h]\centering%
% \graphicsAI[drawing,width=.8\linewidth]{gfx/benchmark1_tagged.pdf}%
% \caption{Benchmarks for the our time-domain and frequency-domain MVDR method running on a GPU. The grey line marks the realtime requirement for the HUGIN AUV to perform full-coverage sectorscan images with a ping rate of 3 pings/s.}\label{2_fig_benchmark}
% \end{figure}
% 
% \section{Comparison}
% 
% Figure \ref{2_fig_holmengraa} contrasts image quality of the mentioned beamformers. The experimental data comes from a HISAS1030 interferometric synthetic aperture sonar (SAS) attached to a HUGIN autonomous underwater vehicle (AUV), both developed by Kongsberg Maritime, Norway. HISAS1030 is a fully digital phased array with 32 hydrophones, 100\,kHz center frequency, 30\,kHz bandwidth, 1.2\,m length, 23$^\circ$ half-power beamwidth (HPBW) and 3-4\,cm theoretical resolution both cross- and along-track. 
% 
% To display the imaging capabilities of the mentioned beamformers, we have processed experimental datasets from the 32 element Kongsberg Maritime HISAS1030 sonar mounted on the HUGIN AUV~\cite{Hansen2009}. HISAS1030 is a high resolution synthetic aperture sonar with an array length of 1.2\,m and operating frequency of 100\,kHz, and it was operated in sidescan mode here. The studied object is the 1500 dwt oil tanker wreck Holmengraa. It is 68\,m long and 9\,m wide, and lies at a slanted seabed at 77\,m depth outside of Horten, Norway. The results are shown in Figure \ref{2_fig_holmengraa}. The MVDR images were processed with parameters $L$=16, $K$=3, and 1\% diagonal loading. For beamspace MVDR we set $N_b=L/2$. LCA was designed with a window database consisting of 5 Kaiser windows, each with different window-parameters from the range $\beta\in[0,10]$, and each steered in 5 distinct directions leaving a total of 25 windows for the LCA to select from.
% 
% A few benchmarks of these methods are presented in Figure \ref{2_fig_benchmark}. On our test system with a quad-core Intel Xeon E5620, 64Gb of RAM and an nVidia Quadro 6000 card, the MVDR methods managed to create images at rates just over 1\,Mpx/s. A single-thread C implementation that was added as reference was outperformed by around 2 orders of magnitude. However, do not consider this comparison fair because while the GPU design is make efficient use of the L1 cache, similar optimisation work was not carried out on the CPU design.






% \begin{table}[h]\centering%\normalsize
% \begin{tabular}[c]{l r r r@{:}  l}\hline
% \rowcolor{tabBlue} & \multicolumn{1}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{arithmetic}$} & \multicolumn{1}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{memory}$} & \multicolumn{2}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{memory}$/BW$_\text{arithmetic}$} \\\hline
%  & & & & \\
% \end{tabular}
% \caption{Nvidia Quadro 6000; Memory bandwidths (BW) compared to the peak arithmetic bandwidth of 1.03 Tflop/s.}\label{tabbandwidth}
% \end{table}



% \begin{table}[b]\centering%\normalsize
% \begin{tabular}[c]{l r r r@{:}  l}\hline
% \rowcolor{tabBlue} & \multicolumn{1}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{arithmetic}$} & \multicolumn{1}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{memory}$} & \multicolumn{2}{>{\columncolor{tabBlue}}c}{\bf BW$_\text{memory}$/BW$_\text{arithmetic}$} \\\hline
% Arithmetic throughput & 1.03 Tflop/s & & \hspace{30pt} 1 & 30 \\
% Global memory & & 36 Gfloats/s & \hspace{30pt} 1 & 30 \\
% Shared memory & & 257 Gfloats/s & 1 & 4 \\
% Registers & & $>$1.5 Tfloats/s & $>$3 & 2~\cite{Vasilyy}
% \end{tabular}
% \caption{Nvidia Quadro 6000: Memory bandwidths (BW) compared to the peak arithmetic bandwidth of 1.03 Tflop/s.}\label{tabbandwidth}
% \end{table}




}


\end{document}

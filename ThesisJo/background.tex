\input{variables}\ifMonolithic\else\input{header}\input{subheader}\fi
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\providecommand*\Fig{}
\renewcommand*\Fig[1]{Fig.~\ref{#1}}

\providecommand*\a{}
\renewcommand*\a{\vec a}
\providecommand*\k{}
\renewcommand*\k{\vec k}
\providecommand*\p{}
\renewcommand*\p{\vec p}
\providecommand*\R{}
\renewcommand*\R{\mat R}
\providecommand*\Ri{}
\renewcommand*\Ri{\R^{-1}}
\providecommand*\eR{}
\renewcommand*\eR{\mat{\hat R}}
\providecommand*\s{}
\renewcommand*\s{\vec s}
\providecommand*\v{}
\renewcommand*\v{\vec v}
\providecommand*\w{}
\renewcommand*\w{\vec w}
\providecommand*\x{}
\renewcommand*\x{\vec x}

\providecommand*\1{}
\renewcommand*\1{\vec 1}

\providecommand*\H{}
\renewcommand*\H{^{\scriptscriptstyle H}}
\providecommand*\T{}
\renewcommand*\T{^{\scriptscriptstyle T}}

\providecommand*\mat{}
\renewcommand\mat[1]{\boldsymbol{#1}}

\providecommand\bmat{}
\renewcommand\bmat[1]{\begin{bmatrix}#1\end{bmatrix}}
%\newcommand\T{^{\scriptscriptstyle T}}


\chapter{Background}

MVDR/LCA:
- Beamforming techniques.

Simulator:
- Scattering theory
- Coordinate systems

Common denominator:
- Image progressing
- High processing computing
- GPUs


Light fast, sound slow.
Sound propagates far, light attenuated.

The aim of this chapter is to review the basic background material on which this thesis is founded.

\section{Wave Propagation}

When a rock is thrown into a pound of water it abruptly displaces water away from the center of impact. 
%This is an unstable state where various physical phenomena wrestle for control. Gravity wants the water back where it was, inertia cause the mass to resist any change in its state of motion.
This results in spherical waves propagating from the displacement center, transporting the kinetic energy of the rock. These waves are described by how their particles move. At the surface particles will move down up and down, and back and forth, in a circular motion. In the depths particles move longitudinally, transporting energy by means of alternating pressure.

The wave equation is the single most important equation governing a wave's propagation through a medium. When the medium is loss-less it can be expressed as:

\begin{align*}
\nabla^2 f(\p,t) - \frac{1}{c^2(\p)}\frac{\partial^2 f(\p,t)}{\partial t^2} = -s(t) \delta(\p-\p_0)
\end{align*}

where $\nabla^2$ is the Laplacian operator.


The wave equation constrains the magnitude of the wavenumber,
%
\begin{align*}
\vec k = \frac{\omega}{c} = \frac{2\pi}{\lambda},
\end{align*}
%
so only the direction of $\k$ varies.

\section{Array Processing}

\begin{figure}[th]
\graphicsAI[width=\linewidth]{gfx/geometry.svg}
\caption{The coordinate system used throughout the thesis.}\label{geometry}
\end{figure}

Consider a monochromatic plane wave impinging on an $M$-element array (\Fig{geometry}). Let the position of sensor $m$ be $\p_m$, th  of sensors at locations 
In this thesis we will relate all geometrical interpretations to the euclidean, spherical coordinate system shown in \Fig{geometry}. When assessing the imaging performance of a sonar its origin will be in the center of the array, but when assessing scenes its origin will be in the center of the image. 

Signal model. Monochromatic, plane wave:
%
\begin{align}
\s[n] = \begin{bmatrix}
         s_0[n] \\ s_1[n] \\ \vdots \\ s_{M-1}[n]
        \end{bmatrix}
      = \begin{bmatrix}
         Ae^{j(\Omega n - \k\T\p_0)} \\
         Ae^{j(\Omega n - \k\T\p_1)} \\
         \vdots \\
         Ae^{j(\Omega n - \k\T\p_{M-1})}
        \end{bmatrix}
      = Ae^{j\Omega n}\a(\k)
\end{align}
%
where $A$ is the signal amplitude and $\Omega$ is normalized angular frequency. $\a(\k)$ is what we call signal's \emph{steering vector}.

A unit length vector $\vec u$ can be written as:
%
\begin{align*}
\vec u =
\begin{bmatrix}
\sin\theta \cos\phi \\
\sin\theta \sin\phi \\
\cos\theta
\end{bmatrix}
\end{align*}
%


\section{Adaptive Beamforming}



\subsection{MVDR}

By definition, the beamformer output $z[n]$ can now be expressed as the weighted sum of all the delayed data samples:
\begin{align}
z[n] = \w\H[n]\x[n] = \bmat{w_0[n]\\w_1[n]\\\vdots\\w_{M-1}[n]}^H \bmat{x_0[n]\\x_1[n]\\\vdots\\x_{M-1}[n]},\label{z}
\end{align}
where $w_m$ is the weight factor assigned to channel $m$. With static weights this would be referred to as the conventional delay-and-sum (DAS) beamformer. A large variety of weighting functions exists here for trading lateral resolution for improved noise suppression (contrast), but one always ends up with a compromise between the two~\cite{Harris1978}.

Various adaptive beamformers target this limitation by allowing the weights to change for each pixel to better fit the dynamic nature of the incoming wavefield. In other words, they attempt to use the \emph{a priori} information present in the data to improve image quality. The MVDR beamformer is one such method. It finds the set of complex weights that minimizes the beamformer's expected output power, while ensuring unity gain in the look direction~\cite{Capon1969}. This is a convex optimization problem that can be solved using Lagrange multipliers to yield the solution
%
\begin{gather}
\vec w[n] = \frac{\Ri[n]\a}{\a\T\Ri[n]\a},\label{weights}
\end{gather}
%
where $\a$ is a steering vector and $\R=E\{\x[n]\x\H[n]\}\in\mathbb{C}^{M,M}$ is the spatial covariance matrix for the full array. Since we pre-steer our data to every pixel in the image we simplify (\ref{weights}) by substituting $\a$ with a row vector $\1$ that represents broadside phase-steering. To estimate $\R$ we compute a sample covariance matrix $\eR$. In this computation we perform some degree of:
%
\begin{itemize}
\item \emph{spatial averaging} to avoid signal cancellation by decorrelating coherent echoes~\cite{Kailath1985};
\item \emph{temporal averaging} over an interval comparable to the pulse length (one to five samples) to maintain true speckle statistics~\cite{Synnevag2009};
\item \emph{diagonal loading} to improve robustness to parameter errors~\cite{Cox1987,Maksym1979}.
\end{itemize}%


\section{Active Sonar}

Most modern active sonar imaging systems are usually far better at resolving details in range than in the angular direction. This is because it is relatively cheap and easy to collect a long and well sampled temporal representation of the incoming wave field, but hard to get the spatial equivalent. It would require a very large array with a lot of sensors, which is costly, complicated and impractical. An alternative is to synthesize a large array from a small array through a coherent combination of data from successive pings, a technique known as synthetic aperture sonar (SAS). Unfortunately, the difficult nature of navigating with high precision under water limits this technique to systems with advanced navigational equipment.

Due to the limitations imposed on hardware, a lot of research is put into improving the part of the digital image formation process. A core component here is the beamformer, a spatial band-pass filter used on the wave field to estimate each pixel value. A way to do this while allowing wide-band signals is to steer coarsely by applying delays to the sensor channels, followed by an individual weighting of them. Using complex weights, this implies fine adjustment of both the amplitude and the phase of the spatial filter. While conventional beamformers apply static weight functions, adaptive methods dynamically tailor the weights to the wave field.

\section{Synethic Aperture Sonar}

For an autonomous underwater vehicle to reach its full 

Most autonomous devices designed today only perform very basic tasks.

One of the areas where very fast where the development of faster and faster processing hardware might play a
One of the technologies in which graphics processing units might make a welcome addition is in autonomous underwater vehicles. 

This thesis will describe a simulator for synthetic aperture sonar that 

\section{Scattering models}


Defining parameters:
- Roughness
- Incident angle
- Frequency


Reflection and scattering from surfaces:

Roughness >> wavelength:
- Roughness > wavelength: Helmholtz-Kirchhoff (physical optics approach) (Hovem). Leads to Huygins priciple.
- Roughness < wavelength: Rayleigh-Rice (perturbation technique) (Hovem). More accurate at slightly rough surfaces.

Rayleigh. chi = 2 k sigma sin(theta): Rayleigh criterion: Surface is acoustically smooth when chi << 1.

\begin{itemize}
\item SWAT (Shallow Water Acoustic Toolset): 
\item Bell's thesis:
\item SIGMA:
\item OpenGL does not support scattered writes. OpenCL does.
\item 2D template approximation:
\item Geometric distortions in SSS \cite{Cobra1992} Bell
\item Sidescan sonar and synthetic aperture sonar. In seafloor coordinates. Maps to orthogonal rendering.
\item Layover causes ambiguity, different seafloor phenomena can cause the same output image. Lots of cornercases when approximating the model in 2D. Instead use a 3D model and project it to a 2D one. Easier to operate, models are more general purpose. Less parameters to adjust.
\item Viewer can be used to train an operator for finding non-trivial objects on the seafloor. Input for automated target recognition standard.
\item Improved image quality of selected object, reduced data collection cost (price estimate?).
\item OpenGL rendering can have infinite resolution, only limited by the pixel density in the image.
\item Accuracy in terms of classification result. Need to embody static effects in a deterministic way. Incoherent synthesis of the image.
\item Sound speed assumed constant.
\item High frequency lead to little (define) penetration, lower range and higher resolution. Often modeled accurately with ray tracing techniques.
\end{itemize}

Model
\begin{itemize}
\item Ray solution: Separate amplitude and phase components of the Helmholtz eq. by applying geometric optics approximation. Ok as long as amplitude varies more slowly with position than the phase. Implications: High frequency, because the curvature of a ray over a wavelength must be small, and the fractional change in the sound speed must be small over a wavelength. Further simplification available by Snell's Law. Fast to compute. Not able to handle diffraction, focal points and caustics, and will cause (too) abrupt changes on distinct changes in sea environment. Can be improved upon with fuzzy beam modeling / Gaussian beam tracing.
\begin{itemize}
\item Pro: Easy to compute. Visual result. Handles complex bathymetry. Array and model response can be accounted for.
\item Con: Only works for high frequency and small sound variations. No diffraction, caustics and focus. Infinite energy caustics/sharp variations. Incoherent(?)
\end{itemize}
\item Normal modes: Separate amplitude and phase into a range dependent term, and a depth dependent term. Assumes minimal range dependence in sound speed profile and depth. Limited near field accuracy. Acoustic field does not need to be calculated at intermediate ranges. Penetration can be modeled. can be calculated 
\begin{itemize}
\item Pro: Ok to compute. Handles penetration. Low frequency, shallow water.
\item Con: Horizontal stratification. Far field only. 
\end{itemize}
\item Parabolic equation: One way propagation. Marching solution. Initial starting solution must be known, often computed with normal mode. Only valid for narrow beams $\pm$20. Able to handle range dependent environments. Computing full field is easy. Computation time is of O(f$^2$), hence mostly useful for low-frequency scenarios. Unable to deal with horizontal refraction (shadow zones from e.g. conical mounts)
\item Fast field programs / Green's function solutions. Exact full wave solution for acoustic fields in horizontally stratified media. Can handle both compressional and shear waves, and hence both fluid and solid media. Far field assumption. Similar to normal mode techniques.
\item Finite element: Scene segmented into triangles or rectangles with a size of one tenth of a wavelength, or less. At each node the wavefield can be determined from the wave equation. Computationally limited to low frequencies.
\item 2D model: Acoustic field in range and depth. Assumes that a wave transmitted in a vertical plane remains in it. Reasonable when the sound speed can be assumed constant in the horizontal plane, and when the seafloor normals are in the vertical range-depth plane (avoid horizontal refraction, or actually reflection).
\end{itemize}


What's new?
\begin{itemize}
\item Tuned for speed using GPUs, combining OpenGL and OpenCL to take advantage of existing functionality for computer graphics with the added flexibility of general purpose programming on the GPUs.
\item Performance to spare: Game-like viewer for the visualization and verification of the rendered scene and corresponding sonar image.
\item First simulator of its kinds aimed towards improved ATR and ultimately better AUVs.
\item 3D models are still novel. 
\end{itemize}

\begin{itemize}
\item SWAT (Shallow Water Acoustic Toolset): 
\item Bell's thesis:
\item SIGMA:
\item OpenGL does not support scattered writes. OpenCL does.
\item 2D template approximation:
\item Geometric distortions in SSS \cite{Cobra1992} Bell
\item Sidescan sonar and synthetic aperture sonar. In seafloor coordinates. Maps to orthogonal rendering.
\item Layover causes ambiguity, different seafloor phenomena can cause the same output image. Lots of cornercases when approximating the model in 2D. Instead use a 3D model and project it to a 2D one. Easier to operate, models are more general purpose. Less parameters to adjust.
\item Viewer can be used to train an operator for finding non-trivial objects on the seafloor. Input for automated target recognition standard.
\item Improved image quality of selected object, reduced data collection cost (price estimate?).
\item OpenGL rendering can have infinite resolution, only limited by the pixel density in the image.
\item Accuracy in terms of classification result. Need to embody static effects in a deterministic way. Incoherent synthesis of the image.
\item Sound speed assumed constant.
\item High frequency lead to little (define) penetration, lower range and higher resolution. Often modeled accurately with ray tracing techniques.
\end{itemize}

Model
\begin{itemize}
\item Ray solution: Separate amplitude and phase components of the Helmholtz eq. by applying geometric optics approximation. Ok as long as amplitude varies more slowly with position than the phase. Implications: High frequency, because the curvature of a ray over a wavelength must be small, and the fractional change in the sound speed must be small over a wavelength. Further simplification available by Snell's Law. Fast to compute. Not able to handle diffraction, focal points and caustics, and will cause (too) abrupt changes on distinct changes in sea environment. Can be improved upon with fuzzy beam modeling / Gaussian beam tracing.
\begin{itemize}
\item Pro: Easy to compute. Visual result. Handles complex bathymetry. Array and model response can be accounted for.
\item Con: Only works for high frequency and small sound variations. No diffraction, caustics and focus. Infinite energy caustics/sharp variations. Incoherent(?)
\end{itemize}
\item Normal modes: Separate amplitude and phase into a range dependent term, and a depth dependent term. Assumes minimal range dependence in sound speed profile and depth. Limited near field accuracy. Acoustic field does not need to be calculated at intermediate ranges. Penetration can be modeled. can be calculated 
\begin{itemize}
\item Pro: Ok to compute. Handles penetration. Low frequency, shallow water.
\item Con: Horizontal stratification. Far field only. 
\end{itemize}
\item Parabolic equation: One way propagation. Marching solution. Initial starting solution must be known, often computed with normal mode. Only valid for narrow beams $\pm$20. Able to handle range dependent environments. Computing full field is easy. Computation time is of O(f$^2$), hence mostly useful for low-frequency scenarios. Unable to deal with horizontal refraction (shadow zones from e.g. conical mounts)
\item Fast field programs / Green's function solutions. Exact full wave solution for acoustic fields in horizontally stratified media. Can handle both compressional and shear waves, and hence both fluid and solid media. Far field assumption. Similar to normal mode techniques.
\item Finite element: Scene segmented into triangles or rectangles with a size of one tenth of a wavelength, or less. At each node the wavefield can be determined from the wave equation. Computationally limited to low frequencies.
\item 2D model: Acoustic field in range and depth. Assumes that a wave transmitted in a vertical plane remains in it. Reasonable when the sound speed can be assumed constant in the horizontal plane, and when the seafloor normals are in the vertical range-depth plane (avoid horizontal refraction, or actually reflection).
\end{itemize}


What's new?
\begin{itemize}
\item Tuned for speed using GPUs, combining OpenGL and OpenCL to take advantage of existing functionality for computer graphics with the added flexibility of general purpose programming on the GPUs.
\item Performance to spare: Game-like viewer for the visualization and verification of the rendered scene and corresponding sonar image.
\item First simulator of its kinds aimed towards improved ATR and ultimately better AUVs.
\item 3D models are still novel. 
\end{itemize}




% The ATR algorithms must, however, be sufficiently fast to process the sensor data onboard the AUV in delayed real-time.

% We have developed a simulator for synthetic aperture sonar (SAS) that creates object templates very quickly with the aid of the massive computing power in graphics processing units (GPUs). It loads a 3D model of the sea floor and an object of interest into OpenGL, where emitted sound waves are modeled with a light source placed at the sonar transmit location. We assume rough, isotropic surfaces that reflects sound energy equally in all directions. This can be modeled with a Lambertian scattering model~\cite{Bell1997} where the intensity of the backscattered sound is said to depend only on the on incidence angle of the transmitted signal onto the model surface. When rendering OpenGL is set up to produce an optical 2D intensity image and depth map that reveals the distance from each pixels to the propagation axis. For maximum flexibility this data is finally combined with OpenCL to produce the image templates.
% 
% By coincidence our implementation is not so different from the SIGMAS+ simulator developed at the NATO Undersea Research Centre (NURC)~\cite{Coiras2009a, Coiras2009b}. They both take advantage of OpenGL to render a 2D image from 3D models, are designed for side-looking sonar, and assume a Lambertian scattering model. However, while SIGMAS+ is geared more towards realistically looking sonar images, and include effects such as noise, we do not. Also, their simulator sums images obtained from multiple OpenGL rendering passes to create the sonar image, while we render once and post-process this result with OpenCL to tailor the sonar image full flexibility. 

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\ifMonolithic\else\input{subfooter}\fi
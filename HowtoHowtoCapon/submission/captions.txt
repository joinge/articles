01
Beamforming principle. Signal signature is first removed by matched filtering. Then - prior to summation - a suitable set of delays, Δ, and weights, <I>w</I>, are applied to focus on a pixel of interest at angle and range (θ,<I>n</I>).

02
MVDR beamforming. For each pixel in range and azimuth,\newline
<I>1.</I> an <I>L</I>x<I>L</I> sample covariance matrix <I>R</I> is computed,
<I>2.</I> the term <I>R</I><sup>-1</sup><I>1</I> is found using a linear equation solver,
<I>3.</I> and the beamformer output <I>z</I> is computed from (6), where <I>w</I> is found by substituting <I>R</I><sup>-1</sup><I>1</I> into (2).

03
Per-pixel computational complexity of the steps in MVDR beamforming (prior to any optimizations). To avoid signal cancellation in an active sonar system we usually set <I>L</I><<I>M/2</I>, in which region the computation of the spatial covariance matrix dominates in terms of arithmetic complexity, especially when performing temporal averaging.

04
Step 1: Building <I>R</I>. This is a visualization of how <I>R</I> could be built in a case with <I>M=5</I> sensors, with subarray size <I>L=3</I> and temporal averaging set to <I>K=1</I>. Here <I>R'<sub>l</sub></I> is the sample covariance matrix for the <I>l</I>th subarray, and $\breve{\R}$ is the average of <I>N<sub>K</sub></I> of these. Note that instead of performing the temporal sum last as here, one could take more temporal samples into consideration in the computation of each <I>r<sub>ij</sub></I>.

05
Arithmetic optimization of computing <I>R</I>: Relative reduction in arithmetic complexity compared to the initial implementation shown in Fig. 3 (higher is better) . Note how the arithmetic count is reduced by a factor 4-10 in the memory optimized case, and by a factor 6-22 in the instruction optimized case.

06
MVDR implementated on a GPU. We do this in 3 steps, where each step process the full image before moving on to the next step. <I>Step 1</I>: The sample covariance matrix <I>R</I> is formed by threads running along its diagonals. This allows spatial averaging to be implemented in a computationally efficient manner and minimizes inter-thread communication. <I>Step 2</I>: <I>R</I><sup>-1</sup><I>1</I> is computed using the heavily optimized batched linear equation solver from Nvidia. <I>Step 3</I>: The beamformer output <I>z</I> is computed in a straight forward fashion by <I>L</I> threads that first sum the subarrays and then apply the MVDR weighting function. A single thread finally sum all the channels up.

07
HISAS sidescan sonar (SSS) image of the shipwreck Holmengraa that lies on a slanted seabed at 77 m depth outside of Horten, Norway. The image was processed with <I>M=32</I>, <I>L=16</I>, <I>K=1</I> and <I>d=1%</I>. Prior to display the image was linearly upinterpolated by a factor 2 in azimuth making its total size 1.46 Mpx. Note how MVDR improves edge definition and reduces noise in shadow regions.

08
MVDR benchmarks. A 1 Mpx image from a <I>M=32</I> channel array was processed for all <I>L</I>, and for <I>K</I>∈{0,1,2}. <I>Top</I>: The time the GPU spent on building <I>R</I>, solving <I>R</I><sup>-1</sup><I>1</I>, and computing <I>z</I>. Note the major speedup of building <I>R</I> when compared to the complexity plot in Fig. 3.
<I>Bottom</I>: Compared to a reference Matlab and single thread C implementation running on a CPU the GPU offered a speedup of 2-3 orders of magnitude, but these numbers are somewhat misleading. If the C implementation was properly optimized we expect the GPU to be no more than a factor 5-10 faster, even if its theoretical peak performance is ~20 times higher than that of the CPU.

09
Execution time of an arithmetic-only and a memory-only version of the MVDR code. A dataset from an <I>M=32</I> array was processed for all <I>L</I> using <I>K=1</I>, and the mean execution time for a 1 Mpx image was used here. From this plot we can infer that the kernel building <I>R</I> is memory bound, as the time the kernel spends performing memory transactions is higher than the corresponding time it spends carrying out arithmetical operations. Furthermore, when the total runtime is larger than the restricted kernels this can largely be attributed to latency, which we can see that building <I>R</I> suffers from with the chosen parameters.

10
Code efficiency. An estimate of the number of floating point operations per second (Flop/s), found by dividing the theoretical complexity curves by actual run-times. This is a cruel measure as it does not include any other instructions than the actual arithmetic operations in the MVDR computation.

11
MVDR benchmarks from Boston HPC centre with the new high-end Nvidia K20 Kepler GPU. The exact same scenario and code as in Fig. 8 was used here. With no code alterations the performance was only improved marginally compared to running on the Quadro 6000.